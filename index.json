[{"uri":"https://gorgonia.org/about/computation-graph/","title":"Computation Graph","tags":[],"description":"Graphs and *Nodes","content":" Gorgonia is Graph based Note: this article takes its inspiration from this blog post\nLike most deep learning libraries such as Tensorflow or Theano, Gorgonia rely on the concept that equations are representable by graphs.\nIt expose the equation graph as an ExprGraph object that can be manipulated by the programmer.\nSo instead of writing:\nfunc main() { fmt.Printf(\u0026#34;%v\u0026#34;, 1+1) } the programmer should write:\nfunc main() { // Create a graph. \tg := gorgonia.NewGraph() // Create a node called \u0026#34;x\u0026#34; with the value 1. \tx := gorgonia.NodeFromAny(g, 1, gorgonia.WithName(\u0026#34;x\u0026#34;)) // Create a node called \u0026#34;y\u0026#34; with the value 1. \ty := gorgonia.NodeFromAny(g, 1, gorgonia.WithName(\u0026#34;y\u0026#34;)) // z := x + y \tz := gorgonia.Must(gorgonia.Add(x, y)) // Create a VM to execute the graph. \tvm := gorgonia.NewTapeMachine(g) // Run the VM. Errors are not checked. \tvm.RunAll() // Print the value of z. \tfmt.Printf(\u0026#34;%v\u0026#34;, z.Value()) } Numerical stability Consider the equation $y = log(1+x)$. This equation is not numerically stable - for very small values of $x$, the answer will most likely be wrong. This is because of the way float64 is designed - a float64 does not have enough bits to be able to tell apart 1 and 1 + 10e-16. In fact, the correct way to do it in Go is to use the built in library function math.Log1p. It can be shown in this simple program:\nfunc main() { fmt.Printf(\u0026#34;%v\\n\u0026#34;, math.Log(1.0+10e-16)) fmt.Printf(\u0026#34;%v\\n\u0026#34;, math.Log1p(10e-16)) }1.110223024625156e-15 // wrong 9.999999999999995e-16 // correct Gorgonia takes care of this using the best implementation to assure numerical stability.\nExpGraph and *Node The ExprGraph is the object holding the equation. This vertices of this graph are the values or operators that compose the equation we want to materialize. Those vertices are represented by a structure called \u0026ldquo;Node\u0026rdquo;. The graph holds pointer to this structure.\nTo create the equation, we need to create an ExprGraph, add some *Nodes, it and linked them together.\nLuckily, we don\u0026rsquo;t have to manage the connections between the nodes manually.\nPlaceholders and Operators The Node can hold some Values (a Value is a Go interface that represents a concrete type such as a scalar or a tensor). But it can also hold Operators.\nAt computation time, the values will flow along the graphs and each node containing an Operator will execute the corresponding code and set the value to the corresponding node.\nGradient computation On top of that, Gorgonia can do both symbolic and automatic differentiation. This page explains how it works in detail.\n"},{"uri":"https://gorgonia.org/reference/exprgraph/","title":"Graph / Exprgraph","tags":[],"description":"","content":"A lot has been said about a computation graph or an expression graph. But what is it exactly? Think of it as an AST for the math expression that you want. Here\u0026rsquo;s the graph for the examples (but with a vector and a scalar addition instead) above:\nBy the way, Gorgonia comes with nice-ish graph printing abilities. Here\u0026rsquo;s an example of a graph of the equation $y = x^2$ and its derivation:\nTo read the graph is easy. The expression builds from bottom up, while the derivations build from top down. This way the derivative of each node is roughly on the same level.\nRed-outlined nodes indicate that it\u0026rsquo;s a root node. Green outlined nodes indicate that they\u0026rsquo;re a leaf node. Nodes with a yellow background indicate that it\u0026rsquo;s an input node. The dotted arrows indicate which node is the gradient node for the pointed-to node.\nConcretely, it says that c42011e840 ($\\frac{\\partial{y}}{\\partial{x}}$) is the gradient node of the input c42011e000 (which is $x$).\n"},{"uri":"https://gorgonia.org/tutorials/hello-world/","title":"Hello World","tags":[],"description":"","content":" This is a step by step tutorial to do a very simple computation with Gorgonia.\nOur goal is to use all the plumbing of Gorgonia to do a simple operation:\n$ f(x,y) = x + y $\nwith x = 2 and y = 5\nhow it works The equation x + y = z can be represented as a graph:\ngraph LR; z[z] -- add(Round edge) add[+] -- x add[+] -- y  To compute the result, we use 4 steps:\n Make a similar graph with Gorgonia sets some values on the nodes x and y then instanciate a graph on a gorgonia vm extract the value from node z *  Create a graph Create an empty expression graph with this method:\ng := gorgonia.NewGraph() Create the nodes We will create some nodes and associate them to the ExprGraph.\nvar x, y, z *gorgonia.Node Create the placeholder x and y are scalar variables, we can create the corresponding node with:\nx = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;x\u0026#34;)) y = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;y\u0026#34;)) the functions take the exprgraph as argument; the resulting node is automatically associated to the graph.\n Now create the addition operator; this operator takes two nodes and returns a new node z:\nif z, err = gorgonia.Add(x, y); err != nil { log.Fatal(err) } the returning node z is added to the graph even if g is not passed to z or to the Add function.\n Set the values We have a ExprGraph that represents the equation z = x + y. Now it\u0026rsquo;s time to assign some values to x and y.\nWe use the Let function:\ngorgonia.Let(x, 2.0) gorgonia.Let(y, 2.5) Run the graph To run the graph and compute the result, we need to instanciate a VM. Let\u0026rsquo;s use the TapeMachine:\nmachine := gorgonia.NewTapeMachine(g) defer machine.Close() and run the graph:\nif err = machine.RunAll(); err != nil { log.Fatal(err) } If a second run is needed, it is mandatory to call the Reset() method of the vm object: machine.Reset()\n Get the result Now the node z holds the result. We can extract its value by calling the Value() method:\nfmt.Printf(\u0026#34;%v\u0026#34;, z.Value()) we could also access the underlying \u0026ldquo;Go\u0026rdquo; value with a call to z.Value().Data() which would return an interface{} holding a float64 in our case\n Final result package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;gorgonia.org/gorgonia\u0026#34; ) func main() { g := gorgonia.NewGraph() var x, y, z *gorgonia.Node var err error // define the expression  x = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;x\u0026#34;)) y = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;y\u0026#34;)) if z, err = gorgonia.Add(x, y); err != nil { log.Fatal(err) } // create a VM to run the program on  machine := gorgonia.NewTapeMachine(g) defer machine.Close() // set initial values then run  gorgonia.Let(x, 2.0) gorgonia.Let(y, 2.5) if err = machine.RunAll(); err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;%v\u0026#34;, z.Value()) }$ go run main.go 4.5"},{"uri":"https://gorgonia.org/tutorials/mnist/","title":"Simple Convolution Neural Net (MNIST)","tags":[],"description":"","content":" About This a step by step tutorial to build and train a convolution neural network on the MNIST dataset.\nThe complete code can be found in the examples directory of the principal Gorgonia repository. The goal of this tutorial is to explain in detail the code. Further explanation of how it works can be found in the book Go Machine Learning Projects\nThe dataset This part is about loading and printing the dataset. If you want to jump straight into the neural net, feel free to skip it and go to The Convolution Neural Net part.\n The training and testing sets can be downloaded from Yann LeCun\u0026rsquo;s MNIST website\n train-images-idx3-ubyte.gz: training set images (9912422 bytes) train-labels-idx1-ubyte.gz: training set labels (28881 bytes) t10k-images-idx3-ubyte.gz: test set images (1648877 bytes) t10k-labels-idx1-ubyte.gz: test set labels (4542 bytes)  As explained on the website, those files hold multiple images or labels encoded in binary. Every image/label starts with a magic number. The encoding/binary package of the standard library of Go makes it easy to read those files.\nThe mnist package As a commodity, Gorgonia has created a package mnist in the examples subdirectory. Its goal is to extract the information from the data and to create tensors.\nThe function readImageFile creates an array of bytes that represents all the images contained in the reader.\nA similar readLabelFile function extracts the labels.\n// Image holds the pixel intensities of an image. // 255 is foreground (black), 0 is background (white). type RawImage []byte // Label is a digit label in 0 to 9 type Label uint8 func readImageFile(r io.Reader, e error) (imgs []RawImage, err error) func readLabelFile(r io.Reader, e error) (labels []Label, err error) Then two functions take care of the conversion from RawImage and Label into tensor.Tensor:\n prepareX prepareY\nfunc prepareX(M []RawImage, dt tensor.Dtype) (retVal tensor.Tensor) func prepareY(N []Label, dt tensor.Dtype) (retVal tensor.Tensor)  The only exported function from the package is Load that reads the files typ from loc and returns tensors of a specific type (float32 or float64):\n// Load loads the mnist data into two tensors // // typ can be \u0026#34;train\u0026#34;, \u0026#34;test\u0026#34; // // loc represents where the mnist files are held func Load(typ, loc string, as tensor.Dtype) (inputs, targets tensor.Tensor, err error) Testing the package Now, let\u0026rsquo;s create a simple main file to validate that the data are loaded.\nThis layout of the test directory is expected:\n$ ls -alhg * -rw-r--r-- 1 staff 375B Nov 11 13:48 main.go testdata: total 107344 drwxr-xr-x 6 staff 192B Nov 11 13:48 . drwxr-xr-x 4 staff 128B Nov 11 13:48 .. -rw-r--r-- 1 staff 7.5M Jul 21 2000 t10k-images.idx3-ubyte -rw-r--r-- 1 staff 9.8K Jul 21 2000 t10k-labels.idx1-ubyte -rw-r--r-- 1 staff 45M Jul 21 2000 train-images.idx3-ubyte -rw-r--r-- 1 staff 59K Jul 21 2000 train-labels.idx1-ubyte Now let\u0026rsquo;s write this simple Go file that will read both test and train data and display the resulting tensors:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;gorgonia.org/gorgonia/examples/mnist\u0026#34; \u0026#34;gorgonia.org/tensor\u0026#34; ) func main() { for _, typ := range []string{\u0026#34;test\u0026#34;, \u0026#34;train\u0026#34;} { inputs, targets, err := mnist.Load(typ, \u0026#34;./testdata\u0026#34;, tensor.Float64) if err != nil { log.Fatal(err) } fmt.Println(typ+\u0026#34; inputs:\u0026#34;, inputs.Shape()) fmt.Println(typ+\u0026#34; data:\u0026#34;, targets.Shape()) } } Run the file:\n$ go run main.go test inputs: (10000, 784) test data: (10000, 10) train inputs: (60000, 784) train data: (60000, 10) We have 60000 pictures of $28\\times28=784$ pixels, 60000 corresponding labels \u0026ldquo;one-hot\u0026rdquo; encoded, and 10000 test files in the test set.\nImage representation Let\u0026rsquo;s draw a picture of the first element:\nimport ( //...  \u0026#34;image\u0026#34; \u0026#34;image/png\u0026#34; \u0026#34;gorgonia.org/gorgonia/examples/mnist\u0026#34; \u0026#34;gorgonia.org/tensor\u0026#34; \u0026#34;gorgonia.org/tensor/native\u0026#34; ) func main() { inputs, targets, err := mnist.Load(\u0026#34;train\u0026#34;, \u0026#34;./testdata\u0026#34;, tensor.Float64) if err != nil { log.Fatal(err) } cols := inputs.Shape()[1] imageBackend := make([]uint8, cols) for i := 0; i \u0026lt; cols; i++ { v, _ := inputs.At(0, i) imageBackend[i] = uint8((v.(float64) - 0.1) * 0.9 * 255) } img := \u0026amp;image.Gray{ Pix: imageBackend, Stride: 28, Rect: image.Rect(0, 0, 28, 28), } w, _ := os.Create(\u0026#34;output.png\u0026#34;) vals, _ := native.MatrixF64(targets.(*tensor.Dense)) fmt.Println(vals[0]) err = png.Encode(w, img) } We are using the native package to access the underlying []float64 backend easily. This operation does not generate new data.\n This produce this png file: and the corresponding label vector that indicates that it is a 5:\n$ go run main.go [0.1 0.1 0.1 0.1 0.1 0.9 0.1 0.1 0.1 0.1] The convolution neural net We are building a 5 layers convolution network. $x_0$ is the input image, as defined previously.\nThe first three layers $i$ are defined this way:\n$ x_{i+1} = Dropout(Maxpool(ReLU(Convolution(x_i,W_i)))) $\nwith $i$ in range 0-2\nThe fourth layer is basically a dropout layer to randomly zeroed some activations:\n$ x_{4} = Dropout(ReLU(x_3\\cdot W_3)) $\nThe final layer applies a simple multiplication and a softmax in order to get an output vector (this vector represent the label predicted):\n$ y = softmax(x_4\\cdot W_4)$\nVariables of the network The learnables parameters are $W_0,W_1,W_2,W_3,W_4$. Other variables of the network are the dropout probabilities $d_0,d_1,d_2,d_3$.\nLet\u0026rsquo;s create a structure to hold the variables and the output node of the model:\ntype convnet struct { g *gorgonia.ExprGraph w0, w1, w2, w3, w4 *gorgonia.Node // weights. the number at the back indicates which layer it\u0026#39;s used for \td0, d1, d2, d3 float64 // dropout probabilities  out *gorgonia.Node } Definition of the learnables The convolution is using a standard $3\\times3$ kernel, and 32 filters. As the images of the dataset are in black and white, we are using only one channel. This lead to the following definition of the weights:\n $W_0 \\in \\mathbb{R}^{32\\times 1\\times3\\times3}$ for the first convolution operator $W_1 \\in \\mathbb{R}^{64\\times 32\\times3\\times3}$ for the second convolution operator $W_2 \\in \\mathbb{R}^{128\\times 64\\times3\\times3}$ for the third convolution operator $W_3 \\in \\mathbb{R}^{128*3*3\\times 625}$ we are preparing the final matrix multiplication, so we need to reshape the 4D input into a matrix (128x3x3). 625 is an arbitrary number. $W_4 \\in \\mathbb{R}^{625\\times 10}$ to reduce the output size to a single vector of 10 entries  In NN optimization, it\u0026rsquo;s commonly known that if you have a middle layer that is smaller than the output and input, you are \u0026ldquo;squeezing\u0026rdquo; useless information. Input is 784; then next layer should be smaller. 625 is a good looking number.\n The dropout probabilities are fixed to idiomatic values:\n $d_0=0.2$ $d_1=0.2$ $d_2=0.2$ $d_3=0.55$  We can now create the structure with the placeholder for the learnables:\n// Note: gorgonia is abbreviated G in this example for clarity func newConvNet(g *G.ExprGraph) *convnet { w0 := G.NewTensor(g, dt, 4, G.WithShape(32, 1, 3, 3), G.WithName(\u0026#34;w0\u0026#34;), G.WithInit(G.GlorotN(1.0))) w1 := G.NewTensor(g, dt, 4, G.WithShape(64, 32, 3, 3), G.WithName(\u0026#34;w1\u0026#34;), G.WithInit(G.GlorotN(1.0))) w2 := G.NewTensor(g, dt, 4, G.WithShape(128, 64, 3, 3), G.WithName(\u0026#34;w2\u0026#34;), G.WithInit(G.GlorotN(1.0))) w3 := G.NewMatrix(g, dt, G.WithShape(128*3*3, 625), G.WithName(\u0026#34;w3\u0026#34;), G.WithInit(G.GlorotN(1.0))) w4 := G.NewMatrix(g, dt, G.WithShape(625, 10), G.WithName(\u0026#34;w4\u0026#34;), G.WithInit(G.GlorotN(1.0))) return \u0026amp;convnet{ g: g, w0: w0, w1: w1, w2: w2, w3: w3, w4: w4, d0: 0.2, d1: 0.2, d2: 0.2, d3: 0.55, } } The learnables are initialized with some values normally sampled using Glorot et al.\u0026rsquo;s algorithm. For more info: All you need is a good init on Arxiv.\n Definition of the network It is now possible to define the network by adding a method to the convnet structure:\nNote: error checking are, once again, removed for clarity\n// This function is particularly verbose for educational reasons. In reality, you\u0026#39;d wrap up the layers within a layer struct type and perform per-layer activations func (m *convnet) fwd(x *gorgonia.Node) (err error) { var c0, c1, c2, fc *gorgonia.Node var a0, a1, a2, a3 *gorgonia.Node var p0, p1, p2 *gorgonia.Node var l0, l1, l2, l3 *gorgonia.Node // LAYER 0 \t// here we convolve with stride = (1, 1) and padding = (1, 1), \t// which is your bog standard convolution for convnet \tc0, _ = gorgonia.Conv2d(x, m.w0, tensor.Shape{3, 3}, []int{1, 1}, []int{1, 1}, []int{1, 1}) a0, _ = gorgonia.Rectify(c0) p0, _ = gorgonia.MaxPool2D(a0, tensor.Shape{2, 2}, []int{0, 0}, []int{2, 2}) l0, _ = gorgonia.Dropout(p0, m.d0) // Layer 1 \tc1, _ = gorgonia.Conv2d(l0, m.w1, tensor.Shape{3, 3}, []int{1, 1}, []int{1, 1}, []int{1, 1}) a1, _ = gorgonia.Rectify(c1) p1, _ = gorgonia.MaxPool2D(a1, tensor.Shape{2, 2}, []int{0, 0}, []int{2, 2}) l1, _ = gorgonia.Dropout(p1, m.d1) // Layer 2 \tc2, _ = gorgonia.Conv2d(l1, m.w2, tensor.Shape{3, 3}, []int{1, 1}, []int{1, 1}, []int{1, 1}) a2, _ = gorgonia.Rectify(c2) p2, _ = gorgonia.MaxPool2D(a2, tensor.Shape{2, 2}, []int{0, 0}, []int{2, 2}) var r2 *gorgonia.Node b, c, h, w := p2.Shape()[0], p2.Shape()[1], p2.Shape()[2], p2.Shape()[3] r2, _ = gorgonia.Reshape(p2, tensor.Shape{b, c * h * w}) l2, _ = gorgonia.Dropout(r2, m.d2) // Layer 3 \tfc, _ = gorgonia.Mul(l2, m.w3) a3, _ = gorgonia.Rectify(fc) l3, _ = gorgonia.Dropout(a3, m.d3) // output decode \tvar out *gorgonia.Node out, _ = gorgonia.Mul(l3, m.w4) m.out, _ = gorgonia.SoftMax(out) return } Training the neural network The input we got from the training set are a matrix $numExample \\times 784$. The convolution operator expects a 4D tensor BCHW. The first thing we need to do is to reshape the input:\nnumExamples := inputs.Shape()[0] inputs.Reshape(numExamples, 1, 28, 28) We will train the network by batch. The batch size is a variable (bs). We create two new tensors that will hold the values and labels of the current batch. Then we instantiate the neural net:\ng := gorgonia.NewGraph() x := gorgonia.NewTensor(g, dt, 4, gorgonia.WithShape(bs, 1, 28, 28), gorgonia.WithName(\u0026#34;x\u0026#34;)) y := gorgonia.NewMatrix(g, dt, gorgonia.WithShape(bs, 10), gorgonia.WithName(\u0026#34;y\u0026#34;)) m := newConvNet(g) m.fwd(x) Cost function We define a cost function we want to minimize based on a simple cross-entropy by multiplying the expected output element-wise and then averaging it:\n$cost = -\\dfrac{1}{bs} \\sum_{i=1}^{bs}(pred^{(i)}\\cdot y^{(i)})$\nlosses := gorgonia.Must(gorgonia.HadamardProd(m.out, y)) cost := gorgonia.Must(gorgonia.Mean(losses)) cost = gorgonia.Must(gorgonia.Neg(cost)) and keep a pointer on the value of the cost for later:\nvar costVal gorgonia.Value gorgonia.Read(cost, \u0026amp;costVal) Then we will perform symbolic backpropagation with:\ngorgonia.Grad(cost, m.learnables()...) Learnables is defined like this:\nfunc (m *convnet) learnables() gorgonia.Nodes { return gorgonia.Nodes{m.w0, m.w1, m.w2, m.w3, m.w4} } The training loop First we need a vm to run the graph, and a solver to adapt the learnables at each step. We also need to bind the dual values of the learnables to actually store the values of the gradient for the solver to work.\nvm := gorgonia.NewTapeMachine(g, gorgonia.BindDualValues(m.learnables()...)) solver := gorgonia.NewRMSPropSolver(gorgonia.WithBatchSize(float64(bs))) defer vm.Close() We define a number of batches that compose an epoch regarding the batchsize:\nbatches := numExamples / bs and then create the training loops:\nfor i := 0; i \u0026lt; *epochs; i++ { for b := 0; b \u0026lt; batches; b++ { // ...  } } Inside the loop: Now we need to extract values from the input tensor (which is $60000 \\times 784$) for each batch. Each input is ($bs\\times 784$). First batch will hold values from 0 to bs-1, second bs to 2*bs-1, and so on. Then the tensor is reshaped into a 4D tensor:\nvar xVal, yVal tensor.Tensor xVal, _ = inputs.Slice(sli{start, end}) yVal, _ = targets.Slice(sli{start, end}) xVal.(*tensor.Dense).Reshape(bs, 1, 28, 28) Then we assign the values to the graph:\ngorgonia.Let(x, xVal) gorgonia.Let(y, yVal) and run the VM and the solver to adapt the weights\nvm.RunAll() solver.Step(gorgonia.NodesToValueGrads(m.learnables())) vm.Reset() That\u0026rsquo;s it, you now have a neural network that can learn.\nConclusion Running the code is relatively slow due to the massive amount of data involved, but it learns. You can get the full code in the Gorgonia\u0026rsquo;s example directory.\nTo save the weights, the user can create two methods of load and save as described in the iris tutorial. Then it is let as an exercise to the reader to code a little utility to use this neural network.\nHave fun!\n"},{"uri":"https://gorgonia.org/getting-started/","title":"Getting Started","tags":[],"description":"Quick start with Gorgonia","content":" Getting gorgonia Gorgonia is go-gettable and supports go modules. To get the library and its dependencies, simply run\n$ go get gorgonia.org/gorgonia First code to do a simple computation create a simple program to see if the plumbing is ok:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;gorgonia.org/gorgonia\u0026#34; ) func main() { g := gorgonia.NewGraph() var x, y, z *gorgonia.Node var err error // define the expression  x = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;x\u0026#34;)) y = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;y\u0026#34;)) if z, err = gorgonia.Add(x, y); err != nil { log.Fatal(err) } // create a VM to run the program on  machine := gorgonia.NewTapeMachine(g) defer machine.Close() // set initial values then run  gorgonia.Let(x, 2.0) gorgonia.Let(y, 2.5) if err = machine.RunAll(); err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;%v\u0026#34;, z.Value()) } running the program should print the result: 4.5\nFor further explanation, please see the Hello World tutorial.\n"},{"uri":"https://gorgonia.org/about/","title":"How Gorgonia works","tags":[],"description":"Articles with a goal to explain how gorgonia works.","content":" about Gorgonia works by creating a computation graph, and then executing it. Think of it as a programming language, but is limited to mathematical functions, and has no branching capability (no if/then or loops). In fact this is the dominant paradigm that the user should be used to thinking about. The computation graph is an AST.\nMicrosoft\u0026rsquo;s CNTK, with its BrainScript, is perhaps the best at exemplifying the idea that building of a computation graph and running of the computation graphs are different things, and that the user should be in different modes of thoughts when going about them.\nWhilst Gorgonia\u0026rsquo;s implementation doesn\u0026rsquo;t enforce the separation of thought as far as CNTK\u0026rsquo;s BrainScript does, the syntax does help a little bit.\ngoing further This chapter contains articles with a goal to explain how gorgonia works.\nThe articles in this section are understanding-oriented, and provides background and context.\n  Computation Graph  Graphs and *Nodes\n Differentiation  How gradient computation works within Gorgonia\n "},{"uri":"https://gorgonia.org/about/differentiation/","title":"Differentiation","tags":[],"description":"How gradient computation works within Gorgonia","content":" about This section is a work in progress and explains how differentiation works\n Automatic Differentiation  This page will explain how automatic differentiation works\n Symbolic Differentiation  This page will explain how symbolic differentiation works\n "},{"uri":"https://gorgonia.org/tutorials/","title":"Tutorials","tags":[],"description":"tutorials on various use-cases","content":" Tutorials Various tutorials to start with various usage of Gorgonia.\nThose tutorials are:\n learning-oriented allows the newcomer to get started are a lesson  Analogy: teaching a small child how to cook\nTutorials available so far  Hello World   Simple Convolution Neural Net (MNIST)   Convnet with CUDA   Multivariate linear regression on Iris Dataset   "},{"uri":"https://gorgonia.org/how-to/","title":"How To","tags":[],"description":"Various howto solve a specific problem with Gorgonia","content":"How to do different machine-learning things with Gorgonia.\nIn this section you will see how Gorgonia can be used to solve various problems.\nThose how-to guides:\n are goal-oriented shows how to solve a specific problem are made of understandable steps  Analogy: a recipe in a cookery book\n Troubleshoot GPU Issues   Drawing the ExprGraph with Graphviz (dot)   Create a tensor from a Dataframe (gota)   Save Weights   "},{"uri":"https://gorgonia.org/reference/","title":"Reference guide","tags":[],"description":"This is a reference guide of Gorgonia. It describes the machinery","content":" Reference This is the reference guide of Gorgonia. The goal of the articles in this section are:\n being information-oriented describing the machinery being accurate and complete  Analogy: a reference encyclopaedia article\n Graph / Exprgraph   Present   CUDA support   Tensor   Solvers   VM   "},{"uri":"https://gorgonia.org/reference/present/","title":"Present","tags":[],"description":"","content":" This page contains material that can be used within presentation.\nLogos   Logos   logo_g.svg  (22 ko)   logo_g_square.png  (142 ko)   logo_horizontal.svg  (25 ko)   logo_vertical.svg  (25 ko)    "},{"uri":"https://gorgonia.org/how-to/troubleshoot-gpu-issues/","title":"Troubleshoot GPU Issues","tags":[],"description":"","content":" This document is a running list of troubleshooting TODOs. Should you run into issues with GPU usage, this document should help.\nThe cu package ships with an application called cudatest which will be helpful in troubleshooting issues.\nTo install cudatest, run\ngo install gorgonia.org/cu/cmd/cudatest This also assumes that you already have installed CUDA, and cuDNN.\nError in Initialization with Multiple GPUs If you are running multiple GPUs, you might run into a message that looks as follows:\nError in initialization, please refer to \u0026#34;https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__INITIALIZE.html\u0026#34; This usually means that one of your GPUs does not support CUDA. You can still run with CUDA if you know at least one of your GPUs supports CUDA.\nFirst, use nvidia-smi to find the running GPUs. An example is provided below\nThu Jul 16 17:41:10 2020 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 450.51.05 Driver Version: 450.51.05 CUDA Version: 11.0 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla K20Xm On | 00000000:06:00.0 Off | 0 | | N/A 33C P8 16W / 235W | 0MiB / 5700MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ | 1 GeForce GT 1030 On | 00000000:07:00.0 On | N/A | | 35% 33C P0 N/A / 30W | 656MiB / 1994MiB | 51% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | 1 N/A N/A XXXX G /usr/lib/xorg/Xorg 270MiB | | 1 N/A N/A XXXX G /usr/bin/PROGRAMNAME 77MiB | | 1 N/A N/A XXXX G /usr/bin/PROGRAMNAME 68MiB | | 1 N/A N/A XXXX G ...AAAAAAAAA= --shared-files 221MiB | +-----------------------------------------------------------------------------+ Here, we see that there are two GPUs:\n GPU ID 0 is Tesla K20Xm. GPU ID 1 is GeForce GT 1030.  The GeForce GT 1030 does not supoprt CUDA. While the Tesla K20Xm does. To remedy this, simply add this environment variable:\nCUDA_VISIBLE_DEVICES=0 cudatest Something like the following should be returned:\n$ CUDA_VISIBLE_DEVICES=0 cudatest CUDA version: 11000 CUDA devices: 1 Device 0 ======== Name : \u0026#34;Tesla K20Xm\u0026#34; Clock Rate: 732000 kHz Memory : 5977800704 bytes Compute : 3.5"},{"uri":"https://gorgonia.org/qol/","title":"qol","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/vanity-import-paths/","title":"Vanity-import-paths","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/reference/cuda/","title":"CUDA support","tags":[],"description":"","content":" Gorgonia comes with CUDA support out of the box. However, usage is specialized. To use CUDA, you must build your application with the build tag cuda, like so:\ngo build -tags=\u0026#39;cuda\u0026#39; . Furthermore, there are some additional requirements:\n CUDA toolkit is required. Installing this installs the nvcc compiler which is required to run your code with CUDA (Be sure to follow the post-installation steps). go install gorgonia.org/gorgonia/cmd/cudagen. This installs the cudagen program. Running cudagen will generate the relevant CUDA related code for Gorgonia. Note that you will need a folder at src\\gorgonia.org\\gorgonia\\cuda modules\\target Only certain ops are supported by the CUDA driver by now. They are implemented in a seperate ops/nn package.  CUDA requires thread affinity, and therefore the OS thread must be locked. runtime.LockOSThread() must be called in the main function where the VM is running. Please cf this wiki for a general information on how to handle this properly within your Go program\n Rationale The main reasons for having such complicated requirements for using CUDA is quite simply performance related. As Dave Cheney famously wrote, cgo is not Go. To use CUDA, cgo is unfortunately required. And to use cgo, plenty of tradeoffs need to be made.\nTherefore the solution was to nestle the CUDA related code in a build tag, cuda. That way by default no cgo is used (well, kind-of - you could still use cblas or blase).\nAbout cudagen The reason for requiring CUDA toolkit and the tool cudagen is because there are many CUDA Compute Capabilities, and generating code for them all would yield a huge binary for no real good reason. Rather, users are encouraged to compile for their specific Compute Capabilities.\n The reason for requiring an explicit specification to use CUDA for which ops is due to the cost of cgo calls. Additional work is being done currently to implement batched cgo calls, but until that is done, the solution is keyhole \u0026ldquo;upgrade\u0026rdquo; of certain ops\n Lastly, the reason for requiring an explicit specification to use CUDA for which ops is due to the cost of cgo calls. Additional work is being done currently to implement batched cgo calls, but until that is done, the solution is keyhole \u0026ldquo;upgrade\u0026rdquo; of certain ops\nOps supported by CUDA As of now, only the very basic simple ops support CUDA:\nElementwise unary operations:\n abs sin cos exp ln log2 neg square sqrt inv (reciprocal of a number) cube tanh sigmoid log1p expm1 softplus  Elementwise binary operations - only arithmetic operations support CUDA:\n add sub mul div pow  From a lot of profiling of this author\u0026rsquo;s personal projects, the ones that really matter are tanh, sigmoid, expm1, exp and cube - basically the activation functions. The other operations do work fine with MKL+AVX and aren\u0026rsquo;t the major cause of slowness in a neural network\nCUDA improvements In a trivial benchmark, careful use of CUDA (in this case, used to call sigmoid) shows impressive improvements over non-CUDA code (bearing in mind the CUDA kernel is extremely naive and not optimized):\nBenchmarkOneMilCUDA-8 300\t3348711 ns/op BenchmarkOneMil-8 50\t33169036 ns/op Example see this tutorial for a complete example\n"},{"uri":"https://gorgonia.org/tutorials/mnist-cuda/","title":"Convnet with CUDA","tags":[],"description":"","content":" This tutorial describes how to run the simple convolutional neural network on a GPU.\nThe example used in this tutorial is based on MNIST. Your development environment should be ready as described in the tutorial \u0026ldquo;Simple convolution neural net (mnist)\u0026rdquo;\nPreparing the CUDA binding The CUDA binding relies on CGO and the official CUDA toolkit. You can install it manually or, if you use AWS, you can rely on an AMI with all the pre-requisites.\nInstalling the CUDA toolkit manually The installation of the CUDA toolkit is out-of-scope of this tutorial. But you must ensure that:\n CUDA toolkit is installed (version 10 has been tested successfully). Installing this installs the nvcc compileri, which is required to run your code with CUDA. you run the post-installation steps  Using AWS EC2 AWS provides AMI with the CUDA toolkit pre-installed. You can have a list of those AMI thanks to this command:\n~ aws ec2 describe-images --owners amazon --filters \u0026#39;Name=state,Values=available\u0026#39; \u0026#39;Name=name,Values=Deep Learning AMI (Ubuntu)*\u0026#39; --query \u0026#39;sort_by(Images, \u0026amp;CreationDate)[].Name\u0026#39; Those AMI have been tested successfully on g3s.xlarge against version 0.9.8 of Gorgonia.\nFor convenience, you can find a terraform file to help you kickstarting a VM on AWS EC2 here\n Preparing the code There is many different hardware. To address the specificities, Gorgonia provides a command that generates binding specifically for your hardware. This function is carried by a specific tool call CUDAgen\nCUDAgen does not play well with go modules, and you need to turn them off.\n Those commands install the cudagen tool and generate the CUDA binding.\n~ export GO111MODULE=off ~ go get gorgonia.org/gorgonia ~ export CGO_CFLAGS=\u0026#34;-I/usr/local/cuda-10.0/include/\u0026#34; ~ export PATH=$PATH:/usr/local/cuda/bin/ ~ go get gorgonia.org/cu ~ go install gorgonia.org/gorgonia/cmd/cudagen ~ $GOPATH/bin/cudagen Running the example Gorgonia\u0026rsquo;s example directory contains a convenet_CUDA example. This example runs a convolution neural network against the MNIST database.\nThe code is similar to the convnet example; the only difference is in the operators import; This version uses the operators\u0026rsquo; from the nnops. This package holds a couple of operator definitions mostly used in neural networks (Conv2D, Maxpool, \u0026hellip;); the definitions have a signature that makes them compatible with their counterpart in CUDA. Package nnops ensure the compatibility with the CPU version of the operator if CUDA is not used.\n Assuming that the tests file are in place in ../testdata (cf the tutorial \u0026ldquo;Simple convolution neural net (mnist)\u0026rdquo; if it\u0026rsquo;s not), you can launch the training phase with a CUDA support by simply running:\ntime go run -tags=\u0026#39;CUDA\u0026#39; main.go -epochs 1 2\u0026gt; /dev/null Epoch 0 599 / 600 [====================================================] 99.83% It is also possible to \u0026ldquo;monitor\u0026rdquo; the CUDA usage by running the nvidia-smi command in a separate window. This should display something like this:\n~ nvidia-smi Sun Feb 16 22:05:15 2020 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 418.87.00 Driver Version: 418.87.00 CUDA Version: 10.1 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Tesla M60 On | 00000000:00:1E.0 Off | 0 | | N/A 54C P0 73W / 150W | 841MiB / 7618MiB | 76% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 18614 C /tmp/go-build629284435/b001/exe/main 372MiB | +-----------------------------------------------------------------------------+"},{"uri":"https://gorgonia.org/getting-started/ubiquitous-language/","title":"Ubiquitous Language and glossary","tags":[],"description":"","content":" This page holds various definitions and glossary that will help you to understand Gorgonia and to communicate with the team (via PR or issues)\nTensors  inner(most) dimension(s) - given a shape, the inner dimensions tend to the right. e.g. in a shape (2,3,4), the inner dimensions are (3, 4). The innermost dimension is 4. outer(most) dimension(s) - given a shape, the outer dimensions tend to the left . e.g. in a shape (2,3,4), the outer dimensions are (2, 3). The outermost dimension is 2. vector - a tensor of rank-1. e.g. (2), (3) \u0026hellip; Vectors will be written [...] column vector (or colvec) - a tensor of rank-2 (i.e. a matrix) with the inner dimension as 1. e.g. (2, 1), (3, 1)\u0026hellip; row vector - a tensor of rank-2 (i.e. a matrix) with the outer dimension as 1. e.g. (1, 2), (1, 3)\u0026hellip; matrix a tensor of rank-2, with arbitrary inner and outer dimensions. e.g (1, 2), (2, 1), (2, 3)\u0026hellip; Matrices will be written in full notation in this doc. This includes colvecs and rowvecs.  "},{"uri":"https://gorgonia.org/getting-started/contributing-doc/","title":"Start contributing to the doc","tags":[],"description":"","content":" If you want to get started contributing to the Gorgonia documentation, this page and its linked topics can help you get started. You don\u0026rsquo;t need to be a developer or a technical writer to make a big impact on the Gorgonia documentation and user experience! All you need for the topics on this page is a GitHub account and a web browser.\nIf you\u0026rsquo;re looking for information on how to start contributing to Gorgonia code repositories, refer to the Contribution guidelines.\nThe basics about the docs The Gorgonia documentation is written in Markdown and processed and deployed using Hugo. The source is in GitHub at https://github.com/gorgonia/gorgonia.github.io. Most of the documentation source is stored in /content/.\nYou can file issues, edit content, and review changes from others, all from the GitHub website. You can also use GitHub\u0026rsquo;s embedded history and search tools.\nLayout of the documentation The documentation follows the layout described in the post What nobody tells you about documentation.\nIt is is divided in 4 sections. Each section is a subdirectory in the content/ directory of the repository.\nTutorials A tutorial:\n is learning-oriented allows the newcomer to get started is a lesson  Analogy: teaching a small child how to cook\nSources of the content in the repo: content/tutorials\nHOW-TO Guides A how-to guide:\n is goal-oriented shows how to solve a specific problem is a series of steps  Analogy: a recipe in a cookery book\nSources of the content in the repo: content/how-to\nExplanation An explanation:\n is understanding-oriented explains provides background and context  Analogy: an article on culinary social history\nSources of the content in the repo: content/about\nReference A reference guide:\n is information-oriented describes the machinery is accurate and complete  Analogy: a reference encyclopaedia article\nSources of the content in the repo: content/reference\nMultiple languages Documentation source is available in multiple languages in /content/. Each page can be translated in any language by adding a two-letter code determined by the ISO 639-1 standard. A file without any suffix defaults to English.\nFor example, French documentation of a page is named page.fr.md.\nImprove documentation fix existing content You can improve the documentation by fixing a bug or a typo in the doc. To improve existing content, you file a pull request (PR) after creating a fork. Those two terms are specific to GitHub. For the purposes of this topic, you don\u0026rsquo;t need to know everything about them, because you can do everything using your web browser.\nCreate new content.  The sources of the repository are maintained in the develop branch. Therefore, this branch must be the base of a new branch and PR should be point to this branch as well.\n To create a new content, please create a new page in the directory corresponding to the topic of the doc (see the paragraph Layout of the documentation)\nIf you have hugo locally, you can create a new page with:\nhugo new content/about/mypage.md otherwise, please create a new page with a header that looks like:\n---title:\u0026#34;The title of the page\u0026#34;date:2020-01-31T14:59:03+01:00draft:false--- your content Then submit a pull request as explained below.\nSubmit a pull request Follow these steps to submit a pull request to improve the Gorgonia documentation.\n On the page where you see the issue, click the \u0026ldquo;edit this page\u0026rdquo; icon at the top right. A new GitHub page appears, with some help text. If you have never created a fork of the Gorgonia documentation repository, you are prompted to do so. Create the fork under your GitHub username, rather than another organization you may be a member of. The fork usually has a URL such as https://github.com/\u0026lt;username\u0026gt;/website, unless you already have a repository with a conflicting name.\nThe reason you are prompted to create a fork is that you do not have access to push a branch directly to the definitive Gorgonia repository.\n The GitHub Markdown editor appears with the source Markdown file loaded. Make your changes. Below the editor, fill in the Propose file change form. The first field is the summary of your commit message and should be no more than 50 characters long. The second field is optional, but can include more detail if appropriate. Click Propose file change. The change is saved as a commit in a new branch in your fork, which is automatically named something like patch-1.\n  Do not include references to other GitHub issues or pull requests in your commit message. You can add those to the pull request description later.\n  The next screen summarizes the changes you made, by comparing your new branch (the head fork and compare selection boxes) to the current state of the base fork and base branch (develop on the gorgonia/gorgonia.github.io repository by default). You can change any of the selection boxes, but don\u0026rsquo;t do that now. Have a look at the difference viewer on the bottom of the screen, and if everything looks right, click Create pull request.  If you don\u0026rsquo;t want to create the pull request now, you can do it later, by browsing to the main URL of the Gorgonia website repository or your fork\u0026rsquo;s repository. The GitHub website will prompt you to create the pull request if it detects that you pushed a new branch to your fork.\n  The Open a pull request screen appears. The subject of the pull request is the same as the commit summary, but you can change it if needed. The body is populated by your extended commit message (if present) and some template text. Read the template text and fill out the details it asks for, then delete the extra template text. If you add to the description fixes #\u0026lt;000000\u0026gt; or closes #\u0026lt;000000\u0026gt;, where #\u0026lt;000000\u0026gt; is the number of an associated issue, GitHub will automatically close the issue when the PR merges. Leave the Allow edits from maintainers checkbox selected. Click Create pull request.\nCongratulations! Your pull request is available in Pull requests.\n  Please limit pull requests to one language per PR. For example, if you need to make an identical change to the same code sample in multiple languages, open a separate PR for each language.\n  Wait for review. If a reviewer asks you to make changes, you can go to the Files changed tab and click the pencil icon on any files that have been changed by the pull request. When you save the changed file, a new commit is created in the branch being monitored by the pull request. If you are waiting on a reviewer to review the changes, proactively reach out to the reviewer once every 7 days. You can also drop into #gorgonia channel on gopherslack, which is a good place to ask for help regarding PR reviews.\n If your change is accepted, a reviewer merges your pull request, and the change is live on the Gorgonia website a few minutes later.\n  This is only one way to submit a pull request. If you are already a Git and GitHub advanced user, you can use a local GUI or command-line Git client instead of using the GitHub UI.\n"},{"uri":"https://gorgonia.org/how-to/dot/","title":"Drawing the ExprGraph with Graphviz (dot)","tags":[],"description":"","content":"The encoding package of Gorgonia contains a function to marshal the ExprGraph into the dot language.\nThis make it possible to use the graphviz program to generate png or svg versions of the graph.\nA simple way to do it:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;gorgonia.org/gorgonia\u0026#34; \u0026#34;gorgonia.org/gorgonia/encoding/dot\u0026#34; ) func main() { g := gorgonia.NewGraph() var x, y *gorgonia.Node // define the expression  x = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;x\u0026#34;)) y = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;y\u0026#34;)) gorgonia.Add(x, y) b, err := dot.Marshal(g) if err != nil { log.Fatal(err) } fmt.Println(string(b)) } Running this program and sending its output into the dot process produces a picture.\nfor example:\n$ go run main.go | dot -Tsvg \u0026gt; dot-example.svg produces this graph:\n"},{"uri":"https://gorgonia.org/misc/","title":"Miscellaneous","tags":[],"description":"","content":" Video related to Gorgonia  Gorgonia, A library that helps facilitate machine learning in Go - Sydney Go Meetup, September 2016 \u0026ldquo;A Funny Thing Happened On The Way To Reimplementing AlphaGo\u0026rdquo; (in Go) by Xuanyi Chew  Articles mentioning Gorgonia  Gorgonia (original post on Xuanyi Chew\u0026rsquo;s blog) Tensor Refactor: A Go Experience Report Think like a vertex: using Go\u0026rsquo;s concurrency for graph computation  "},{"uri":"https://gorgonia.org/tutorials/iris/","title":"Multivariate linear regression on Iris Dataset","tags":[],"description":"","content":" About We will use Gorgonia to create a linear regression model.\nThe goal is, to predict the species of the Iris flowers given the characteristics:\n sepal_length sepal_width petal_length petal_width  The species we want to predict are:\n setosa virginica versicolor  The goal of this tutorial is to use Gorgonia to find the correct values of $\\Theta$ given the iris dataset, in order to write a CLI utility that would look like this:\n./iris sepal length: 5 sepal width: 3.5 petal length: 1.4 sepal length: 0.2 It is probably a setosa This tutorial is for academic purpose. Its goal is to describe how to do this with Gorgonia; It is not the state of the art answer to this particular problem.\n Mathematical representation We will consider that the species of Iris if a function of its sepal length and width as well as its petal length and width.\nTherefore, if we consider that $y$ is the value of the species, we the equation we would like to solve is:\n$$ y = \\theta_0 + \\theta_1 * sepal\\_length + \\theta_2 * sepal\\_width + \\theta_3 * petal\\_length + \\theta_4 * petal\\_width$$\nLet\u0026rsquo;s consider the vectors $x$ and $\\Theta$ such as:\n$$ x = \\begin{bmatrix} sepal\\_length \u0026amp; sepal\\_width \u0026amp; petal\\_length \u0026amp; petal\\_width \u0026amp; 1\\end{bmatrix}$$\n$$ \\Theta = \\begin{bmatrix} \\theta_4 \\theta_3 \\theta_2 \\theta_1 \\theta_0 \\end{bmatrix} $$\nWe have\n$$y = x\\cdot\\Theta$$\nLinear regression To find the correct values, we will use a linear regression. We will encode the data (the true facts from observation of different flowers) into a matrix $X$ containing 5 columns (sepal length, sepal width, petal length, petal width and 1 for the bias). A row of the matrix represent a flower.\nThe we will encode the corresponding species into a column vector $Y$ with float values.\n setosa = 1.0 virginica = 2.0 versicolor = 3.0  In the learning phase, the cost is expressed like this:\n$cost = \\dfrac{1}{m} \\sum_{i=1}^m(X^{(i)}\\cdot\\Theta-Y^{(i)})^2$\nWe will use the gradient descent to lower the cost and get the accurate values for $\\Theta$\nIt is possible to get the exact $\\theta$ values with the Normal Equation $$ \\theta = \\left( X^TX \\right)^{-1}X^TY $$ See this gist for a basic implementation with Gonum.\n Generate the training set with gota (dataframe) First, let\u0026rsquo;s generate the training data. We use a dataframe to do this smoothly.\nSee this howto for more info about using the dataframe\n func getXYMat() (*mat.Dense, *mat.Dense) { f, err := os.Open(\u0026#34;iris.csv\u0026#34;) if err != nil { log.Fatal(err) } defer f.Close() df := dataframe.ReadCSV(f) xDF := df.Drop(\u0026#34;species\u0026#34;) toValue := func(s series.Series) series.Series { records := s.Records() floats := make([]float64, len(records)) for i, r := range records { switch r { case \u0026#34;setosa\u0026#34;: floats[i] = 1 case \u0026#34;virginica\u0026#34;: floats[i] = 2 case \u0026#34;versicolor\u0026#34;: floats[i] = 3 default: log.Fatalf(\u0026#34;unknown iris: %v\\n\u0026#34;, r) } } return series.Floats(floats) } yDF := df.Select(\u0026#34;species\u0026#34;).Capply(toValue) numRows, _ := xDF.Dims() xDF = xDF.Mutate(series.New(one(numRows), series.Float, \u0026#34;bias\u0026#34;)) fmt.Println(xDF.Describe()) fmt.Println(yDF.Describe()) return mat.DenseCopyOf(\u0026amp;matrix{xDF}), mat.DenseCopyOf(\u0026amp;matrix{yDF}) } This returns two matrices we can use in Gorgonia.\nCreate the expression graph The equation $X\\cdot\\Theta$ is represented as an ExprGraph:\nfunc getXY() (*tensor.Dense, *tensor.Dense) { x, y := getXYMat() xT := tensor.FromMat64(x) yT := tensor.FromMat64(y) // Get rid of the last dimension to create a vector \ts := yT.Shape() yT.Reshape(s[0]) return xT, yT } func main() { xT, yT := getXY() g := gorgonia.NewGraph() x := gorgonia.NodeFromAny(g, xT, gorgonia.WithName(\u0026#34;x\u0026#34;)) y := gorgonia.NodeFromAny(g, yT, gorgonia.WithName(\u0026#34;y\u0026#34;)) theta := gorgonia.NewVector( g, gorgonia.Float64, gorgonia.WithName(\u0026#34;theta\u0026#34;), gorgonia.WithShape(xT.Shape()[1]), gorgonia.WithInit(gorgonia.Uniform(0, 1))) pred := must(gorgonia.Mul(x, theta)) // Saving the value for later use  var predicted gorgonia.Value gorgonia.Read(pred, \u0026amp;predicted) Gorgonia is higly optimized; it heavily plays with pointers and memory to get good performances. Therefore, calling the Value() method of a *Node at runtime (during the execution process), may lead to incorrect results. If we need to access a specific value of a *Node at runtime (for example during the learning phase), we need to keep a reference to its underlying Value. This is why we use the Read method here. predicted will hold a Value containing the result of $X\\cdot\\Theta$ at anytime.\n Preparing the gradient computation We will use Gorgonia\u0026rsquo;s Symbolic differentiation capability.\nFirst, we will create the cost function, and use a solver to perform a gradient descent to lower the cost.\nCreate the node holding the cost We complete the exprgraph by adding the cost ($cost = \\dfrac{1}{m} \\sum_{i=1}^m(X^{(i)}\\cdot\\Theta-Y^{(i)})^2$)\nsquaredError := must(gorgonia.Square(must(gorgonia.Sub(pred, y)))) cost := must(gorgonia.Mean(squaredError)) We want to lower this cost, so we evaluate the gradient wrt to $\\Theta$:\nif _, err := gorgonia.Grad(cost, theta); err != nil { log.Fatalf(\u0026#34;Failed to backpropagate: %v\u0026#34;, err) } The gradient descent We are using the mechanism of the gradient descent. This means that we use the gradient to modulate the parameters $\\Theta$ step by step.\nThe basic gradient descent is implemented by Vanilla Solver of Gorgonia. We set the learning rate $\\gamma$ to be 0.001.\nsolver := gorgonia.NewVanillaSolver(gorgonia.WithLearnRate(0.001)) And at each step, we will ask the solver to update the $\\Theta$ parameters thanks to its gradient. Therefore, we set an update variable that we will pass to the solver at each iteration\nThe gradient descent will update the all the values passed into []gorgonia.ValueGrad at each step according this equation: ${\\displaystyle x^{(k+1)}=x^{(k)}-\\gamma \\nabla f\\left(x^{(k)}\\right)}$ It is important to understand that the solver works on Values and not on Nodes. But to make things easy, ValueGrad is an interface{} fulfilled by the *Node structure.\n In our case, we want to optimize $\\Theta$ and ask the solver will update its value like this:\n${\\displaystyle \\Theta^{(k+1)}=\\Theta^{(k)}-\\gamma \\nabla f\\left(\\Theta^{(k)}\\right)}$\nTo do so, we need to pass $\\Theta$ to the Step method of the Solver:\nmodel := []gorgonia.ValueGrad{theta} // ... if err = solver.Step(model); err != nil { log.Fatal(err) } The learning iterations Now that we have the principle, we need to run the computation with a vm several times so the gradient descent\u0026rsquo;s magic can happen.\nLet\u0026rsquo;s create a vm to execute the graph (and do the gradient computation):\nmachine := gorgonia.NewTapeMachine(g, gorgonia.BindDualValues(theta)) defer machine.Close() We will ask the solver to update the parameter $\\Theta$ wrt to its gradient. Therefore we must instruct the TapeMachine to store the value of $\\Theta$ as well as its derivative (its dual value). We do this with the BindDualValues function.\n Now let\u0026rsquo;s create the loop and execute the graph at each step; the machine will learn!\niter := 1000000 var err error for i := 0; i \u0026lt; iter; i++ { if err = machine.RunAll(); err != nil { fmt.Printf(\u0026#34;Error during iteration: %v: %v\\n\u0026#34;, i, err) break } if err = solver.Step(model); err != nil { log.Fatal(err) } machine.Reset() // Reset is necessary in a loop like this } Getting some infos We can dump some info about the learning process by using this call\nfmt.Printf(\u0026#34;theta: %2.2f Iter: %v Cost: %2.3f Accuracy: %2.2f \\r\u0026#34;, theta.Value(), i, cost.Value(), accuracy(predicted.Data().([]float64), y.Value().Data().([]float64))) with accuracy defined like this:\nfunc accuracy(prediction, y []float64) float64 { var ok float64 for i := 0; i \u0026lt; len(prediction); i++ { if math.Round(prediction[i]-y[i]) == 0 { ok += 1.0 } } return ok / float64(len(y)) } This will display a line like this during the learning process:\ntheta: [ 0.26 -0.41 0.44 -0.62 0.83] Iter: 26075 Cost: 0.339 Accuracy: 0.61 Save the weights Once the training is done, we save the values of $\\Theta$ to be able to do some predictions:\nfunc save(value gorgonia.Value) error { f, err := os.Create(\u0026#34;theta.bin\u0026#34;) if err != nil { return err } defer f.Close() enc := gob.NewEncoder(f) err = enc.Encode(value) if err != nil { return err } return nil } Create a simple CLI for predictions First, let\u0026rsquo;s load the parameters from the training phase:\nfunc main() { f, err := os.Open(\u0026#34;theta.bin\u0026#34;) if err != nil { log.Fatal(err) } defer f.Close() dec := gob.NewDecoder(f) var thetaT *tensor.Dense err = dec.Decode(\u0026amp;thetaT) if err != nil { log.Fatal(err) } Then, let\u0026rsquo;s create the model (the exprgraph) like we did before:\nA real application would probably have shared the model in a separate package\n g := gorgonia.NewGraph() theta := gorgonia.NodeFromAny(g, thetaT, gorgonia.WithName(\u0026#34;theta\u0026#34;)) values := make([]float64, 5) xT := tensor.New(tensor.WithBacking(values)) x := gorgonia.NodeFromAny(g, xT, gorgonia.WithName(\u0026#34;x\u0026#34;)) y, err := gorgonia.Mul(x, theta) Then enter a for loop that will get info from stdin, do the computation and display the result:\nmachine := gorgonia.NewTapeMachine(g) values[4] = 1.0 for { values[0] = getInput(\u0026#34;sepal length\u0026#34;) values[1] = getInput(\u0026#34;sepal width\u0026#34;) values[2] = getInput(\u0026#34;petal length\u0026#34;) values[3] = getInput(\u0026#34;petal width\u0026#34;) if err = machine.RunAll(); err != nil { log.Fatal(err) } switch math.Round(y.Value().Data().(float64)) { case 1: fmt.Println(\u0026#34;It is probably a setosa\u0026#34;) case 2: fmt.Println(\u0026#34;It is probably a virginica\u0026#34;) case 3: fmt.Println(\u0026#34;It is probably a versicolor\u0026#34;) default: fmt.Println(\u0026#34;unknown iris\u0026#34;) } machine.Reset() } This is a helper function to get the input:\nfunc getInput(s string) float64 { reader := bufio.NewReader(os.Stdin) fmt.Printf(\u0026#34;%v: \u0026#34;, s) text, _ := reader.ReadString(\u0026#39;\\n\u0026#39;) text = strings.Replace(text, \u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;, -1) input, err := strconv.ParseFloat(text, 64) if err != nil { log.Fatal(err) } return input } Now we can go build or go run the code, and voil! We have a fully autonomous CLI that can predict the iris species regarding its features:\n$ go run main.go sepal length: 4.4 sepal widt: 2.9 petal length: 1.4 petal width: 0.2 It is probably a setosa sepal length: 5.9 sepal widt: 3.0 petal length: 5.1 petal width: 1.8 It is probably a virginica Conclusion This is a step by step example. You can now play with the initialization values of theta, or change to solver to see how thing goes within Gorgonia.\nThe full code can be found in the example of the Gorgonia project.\nBonus: visual representation It is possible to visualize the dataset using the Gonum plotter libraries. Here is a simple example on how to achieve it:\nimport ( \u0026#34;gonum.org/v1/plot\u0026#34; \u0026#34;gonum.org/v1/plot/plotter\u0026#34; \u0026#34;gonum.org/v1/plot/plotutil\u0026#34; \u0026#34;gonum.org/v1/plot/vg\u0026#34; \u0026#34;gonum.org/v1/plot/vg/draw\u0026#34; ) func plotData(x []float64, a []float64) []byte { p, err := plot.New() if err != nil { log.Fatal(err) } p.Title.Text = \u0026#34;sepal length \u0026amp; width\u0026#34; p.X.Label.Text = \u0026#34;length\u0026#34; p.Y.Label.Text = \u0026#34;width\u0026#34; p.Add(plotter.NewGrid()) l := len(x) / len(a) for k := 1; k \u0026lt;= 3; k++ { data0 := make(plotter.XYs, 0) for i := 0; i \u0026lt; len(a); i++ { if k != int(a[i]) { continue } x1 := x[i*l+0] // sepal_length \ty1 := x[i*l+1] // sepal_width \tdata0 = append(data0, plotter.XY{X: x1, Y: y1}) } data, err := plotter.NewScatter(data0) if err != nil { log.Fatal(err) } data.GlyphStyle.Color = plotutil.Color(k - 1) data.Shape = \u0026amp;draw.PyramidGlyph{} p.Add(data) p.Legend.Add(fmt.Sprint(k), data) } w, err := p.WriterTo(4*vg.Inch, 4*vg.Inch, \u0026#34;png\u0026#34;) if err != nil { panic(err) } var b bytes.Buffer writer := bufio.NewWriter(\u0026amp;b) w.WriteTo(writer) ioutil.WriteFile(\u0026#34;out.png\u0026#34;, b.Bytes(), 0644) return b.Bytes() }"},{"uri":"https://gorgonia.org/how-to/dataframe/","title":"Create a tensor from a Dataframe (gota)","tags":[],"description":"","content":" This howto explains how to create a tensor from a dataframe using gota The goal is to read a csv file and create a *tensor.Dense with shape (2,2).\nCreate the dataframe from a csv file Consider a csv file with the following content:\nsepal_length,sepal_width,petal_length,petal_width,species 5.1 ,3.5 ,1.4 ,0.2 ,setosa 4.9 ,3.0 ,1.4 ,0.2 ,setosa 4.7 ,3.2 ,1.3 ,0.2 ,setosa 4.6 ,3.1 ,1.5 ,0.2 ,setosa 5.0 ,3.6 ,1.4 ,0.2 ,setosa ... This is extract from the Iris flower data set. A copy of the dataset can be found here\n We want to create a tensor with all values but the species.\nCreate the dataframe with gota. gota\u0026rsquo;s dataframe package has a function ReadCSV that takes an io.Reader as argument.\nf, err := os.Open(\u0026#34;iris.csv\u0026#34;) if err != nil { log.Fatal(err) } defer f.Close() df := dataframe.ReadCSV(f) df is a DataFrame that contains all the data present in the file.\ngota uses te first line of the CSV to reference the columns in the dataframe\n Let\u0026rsquo;s remove the species column:\nxDF := df.Drop(\u0026#34;species\u0026#34;) Convert the dataframe into a matrix To make things easier, we will convert our dataframe into a Matrix as defined by gonum (see the matrix godoc). matrix is an interface. gota\u0026rsquo;s dataframe does not fulfill the Matrix interface. As described into gota\u0026rsquo;s documentation, we create a wrapper around DataFrame to fulfil the Matrix interface.\ntype matrix struct { dataframe.DataFrame } func (m matrix) At(i, j int) float64 { return m.Elem(i, j).Float() } func (m matrix) T() mat.Matrix { return mat.Transpose{Matrix: m} } Create the tensor Now we can create a *Dense tensor thanks to the function tensor.FromMat64 by wrapping the dataframe into the matrix structure.\nxT := tensor.FromMat64(mat.DenseCopyOf(\u0026amp;matrix{xDF}))"},{"uri":"https://gorgonia.org/how-to/save-weights/","title":"Save Weights","tags":[],"description":"","content":" Goal The goal of this howto is to describe a way to save the values of the nodes and to restore them.\nImplementation The best thing you can do right now is to save the value of the corresponding nodes and restore them.\nThe tensors are fulfilling the GobEncode and GobDecode interface and this is the best option. You can also save the backend as a slice of elements but this is a little bit trickier.\nHere is a sample code to do so (it is not optimized at all, feel free to amend it):\npackage main import ( \u0026#34;encoding/gob\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;gorgonia.org/gorgonia\u0026#34; \u0026#34;gorgonia.org/tensor\u0026#34; ) var ( backup = \u0026#34;/tmp/example_gorgonia\u0026#34; ) func main() { g := gorgonia.NewGraph() var x, y, z *gorgonia.Node var err error // Create the graph  x = gorgonia.NewTensor(g, gorgonia.Float64, 2, gorgonia.WithShape(2, 2), gorgonia.WithName(\u0026#34;x\u0026#34;)) y = gorgonia.NewTensor(g, gorgonia.Float64, 2, gorgonia.WithShape(2, 2), gorgonia.WithName(\u0026#34;y\u0026#34;)) if z, err = gorgonia.Add(x, y); err != nil { log.Fatal(err) } // Init variables  xT, yT, err := readFromBackup() if err != nil { log.Println(\u0026#34;cannot read backup, doing init\u0026#34;, err) xT = tensor.NewDense(gorgonia.Float64, []int{2, 2}, tensor.WithBacking([]float64{0, 1, 2, 3})) yT = tensor.NewDense(gorgonia.Float64, []int{2, 2}, tensor.WithBacking([]float64{0, 1, 2, 3})) } err = gorgonia.Let(x, xT) if err != nil { log.Fatal(err) } err = gorgonia.Let(y, yT) if err != nil { log.Fatal(err) } // create a VM to run the program on  machine := gorgonia.NewTapeMachine(g) defer machine.Close() if err = machine.RunAll(); err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;%v\u0026#34;, z.Value()) err = save([]*gorgonia.Node{x, y}) if err != nil { log.Fatal(err) } } func readFromBackup() (tensor.Tensor, tensor.Tensor, error) { f, err := os.Open(backup) if err != nil { return nil, nil, err } defer f.Close() dec := gob.NewDecoder(f) var xT, yT *tensor.Dense log.Println(\u0026#34;decoding xT\u0026#34;) err = dec.Decode(\u0026amp;xT) if err != nil { return nil, nil, err } log.Println(\u0026#34;decoding yT\u0026#34;) err = dec.Decode(\u0026amp;yT) if err != nil { return nil, nil, err } return xT, yT, nil } func save(nodes []*gorgonia.Node) error { f, err := os.Create(backup) if err != nil { return err } defer f.Close() enc := gob.NewEncoder(f) for _, node := range nodes { err := enc.Encode(node.Value()) if err != nil { return err } } return nil } which gives:\n$ go run main.go 2019/10/28 08:07:26 cannot read backup, doing init open /tmp/example_gorgonia: no such file or directory 0 2 4 6 $ go run main.go 2019/10/28 08:07:29 decoding xT 2019/10/28 08:07:29 decoding yT 0 2 4 6"},{"uri":"https://gorgonia.org/reference/tensor/","title":"Tensor","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/reference/vm/gomachine/","title":"Go Machine","tags":[],"description":"This page describes the plumbing inside the Go Machine","content":" This page explains the plumbing inside the GoMachine.\nGoMachine is an experimental feature hold in the xvm package. The API of the package and its name may change.\nThis document is based on commit 7538ab3\nThe states of the nodes The principle relies on the state of the nodes.\nAs explained in Lexical Scanning in Go:\n a state represents where we are an action represents what we do actions result in a new state  As of today, the GoMachine expects a node to be in those possible states:\n waiting for input emitting output  If a node is carrying an operator may have an extra state:\n computing  Later, a new state will eventually be added when implementing automatic differentiation: computing gradient\n This leads to this state graph of the possible states of a node:\ngraph LR; A(Initial Stage) -- BB{input is an op} BB --|no| D[Emit output] BB --|yes| B[Waiting for input] B -- C{inputs == arity} C --|no| B C --|yes| Computing Computing -- E{Has error} E --|no| D E --|yes| F D -- F(end)  Implementation The node is a private structure:\ntype node struct { // ... } We define a type stateFn that represents an action to perform on a *node in a specific context, and returns a new state. This type is a func:\ntype stateFn func(context.Context, *node) stateFn Note: It is the responsibility of every state function to handle context cancelation mechanism.\nWe define four functions of type stateFn to implement the actions required by the node:\nfunc defaultState(context.Context, *node) stateFn { ... } func receiveInput(context.Context, *node) stateFn { ... } func computeFwd(context.Context, *node) stateFn { ... } func emitOutput(context.Context, *node) stateFn { ... } Note: the end state is nil (the zero value of the stateFn)\nRunning the state machine Each node is a state machine. To run it, we set a method run that takes a context as an argument.\nfunc (n *node) Compute(ctx context.Context) error { for state := defaultState; state != nil; { state = state(ctx, n) } return n.err } Note: the *node stores an error that should be set by a stateFn that indicates the reason why it broke the state machine (for example, if an error occurs during the computation, this error contains the reason)\nThen every *node is triggered in its own goroutine by the machine.\nState modification on event We use the paradigm of reactive programming to switch from a state to another.\nA change in the *node structure triggers an action that induce the change of state.\nFor example, let\u0026rsquo;s take a simple calculator that the performs a+b.\n $+$ is waiting for two inputs values to do the sum $a$ and $b$ $a$ is waiting for a value $b$ is waiting for a value  let\u0026rsquo;s send a value to $a$\u0026hellip; $+$ should be notified of this event, receive the value, and expect one more value.\nThen we send a value to $b$, $+$ is notified; it receives the value, and change its state to compute.\nThen it sends the result to whoever is interested in using it.\nIn Go send and receive events are easily performeded with channels.\nThe node structure owns two channels, one to receive the input (inputC), and one to emit the output (outputC):\ntype node struct { outputC chan gorgonia.Value inputC chan ioValue err error // ... } Communication HUB Now we have all nodes running in goroutines, we need to wire them together to actually compute a formulae.\nFor example in: $ a\\times x+b$, we need to send the result of $a\\times x$ into the node carrying the addition operator.\nwhich is roughly:\nvar aTimesX *node{op: mul} var aTimesXPlusB *node{op: sum} var a,b,c gorgonia.Value aTimesX.inputC \u0026lt;- a aTimesX.inputC \u0026lt;- x aTimesXPlusB.inputC \u0026lt;- \u0026lt;- aTimesX.outputC aTimesXPlusB.inputC \u0026lt;- \u0026lt;- b The problem is that a channel is not a \u0026ldquo;topic\u0026rdquo; and it does not handle subscriptions natively. The first consumer takes a value, and drain the channel.\nTherefore if we take this equation $(a + b) \\times c + (a + b) \\times d$, the implementation would not work:\n1 2 3 4 5 6 7 8 9 10 11 12  var aPlusB *node{op: add} var aPlusBTimesC *node{op: mul} var aPlusBTimesCPlusAPlusB *node{op: add} var a,b,c gorgonia.Value aPlusB.inputC \u0026lt;- a aPlusB.inputC \u0026lt;- b aPlusBTimesC.inputC \u0026lt;- \u0026lt;- aPlusB.outputC aPlusBTimesC.inputC \u0026lt;- c aPlusBTimesCPlusAPlusB \u0026lt;- \u0026lt;- aPlusBTimesC.outputC aPlusBTimesCPlusAPlusB \u0026lt;- \u0026lt;- aPlusB.outputC // Deadlock   This will provide a deadlock because aPlusB.outputC is emptied at line 9 and therefore line 12 will never receive value anymore.\nThe solution is to use temporary channels and a broadcast mechanism as described in the article Go Concurrency Patterns: Pipelines and cancellation.\nPublish / subscribe A node is publishing some content to some subscribers. A node is also subscribing for content sent by publishers.\nWe setup two structures:\ntype publisher struct { id int64 publisher \u0026lt;-chan gorgonia.Value subscribers []chan\u0026lt;- gorgonia.Value } type subscriber struct { id int64 publishers []\u0026lt;-chan gorgonia.Value subscriber chan\u0026lt;- ioValue } Each node providing output via the outputC is a publisher, and all the nodes in the graph reaching this node are its subscribers. This defines a publisher object. The ID of the object is the ID of the node providing its output.\nEach node expecting inputs via its inputC is a subscriber. The publishers are the node reached by this node in the *ExprGraph\nMerge and broadcast publishers are broadcasting their data to the subscriber by calling\nfunc broadcast(ctx context.Context, globalWG *sync.WaitGroup, ch \u0026lt;-chan gorgonia.Value, cs ...chan\u0026lt;- gorgonia.Value) { ... }  subscribers are merging the results from the publishers by calling:\nfunc merge(ctx context.Context, globalWG *sync.WaitGroup, out chan\u0026lt;- ioValue, cs ...\u0026lt;-chan gorgonia.Value) { ... } Note: both functions are handling context cancelation\npubsub To actually wire all the publishers and subscribers, we use a top level structure pubsub\ntype pubsub struct { publishers []*publisher subscribers []*subscriber } pubsub is in charge of setting up the network of channels.\nThen a run(context.Context) method is triggering the broadcast and merge for all elements:\nfunc (p *pubsub) run(ctx context.Context) (context.CancelFunc, *sync.WaitGroup) { ... } This method returns a context.CancelFunc and a sync.WaitGroup that will be down to zero when all pubsubs are settled after a cancelation.\nabout ioValue The subscriber have a single input channel; the input values can be sent in any order. The subscriber's merge function tracks the order of the subscribers and wrap the value into the ioValue structure and add the position of the operator emmiting the value:\ntype ioValue struct { pos int v gorgonia.Value } The machine The Machine is the only exported structure of the package.\nIt is a support for nodes and pubsub.\ntype Machine struct { nodes []*node pubsub *pubsub } Creating a machine A machine is created from an *ExprGraph by calling\nfunc NewMachine(g *gorgonia.ExprGraph) *Machine { ... } Under the hood, it parses the graph and generates a *node for each *gorgonia.Node. If a node carries an Op (= an object that implements a Do(... Value) Value method), a pointer to the Op is added to the structure.\nfor transitioning, the package declares a Doer interface. This interface is fulfilled by the *gorgonia.Node structure.\n Two special cases are handled:\n the top-level node of the *ExprGraph have outputC = nil the bottom nodes of the *ExprGraph have inputC = nil  Then the NewMachine calls the createNetwork methods to create the *pubsub elements.\nRunning the machine a call to the Run method of the Machine triggers the computation. The call to this function is blocking. It returns an error and stop the process if: - all the nodes have reached their final states - one node\u0026rsquo;s execution state returns an error\nin case of error, a cancel signal is automatically sent to the *pubsub infrastructure to avoid leackage.\nClosing the machine After the computation, it is safe to call Close to avoid memory leak. Closecloses all the channels hold by the *node and the *pubsub\nMisc It is important to notice that the machine is independent from the *ExprGraph. Therefore the values hold by the *gorgonia.Node are not updated.\nTo access the data, you must call the GetResult method of the machine. This method takes a node ID as input (*node and *gorgonia.Node have the same IDs)\nEx:\nvar add, err := gorgonia.Add(a,b) fmt.Println(machine.GetResult(add.ID()))"},{"uri":"https://gorgonia.org/reference/vm/lispmachine/","title":"LispMachine","tags":[],"description":"","content":"The LispMachine was designed to take a graph as an input, and executes directly on the nodes of the graph. If the graph change, simply create a new lightweight LispMachine to execute it on. The LispMachine is suitable for tasks such as creating recurrent neural networks without a fixed size.\nThe trade-off is that executing a graph on LispMachine is generally slower than on TapeMachine, given the same static \u0026ldquo;image\u0026rdquo; of a graph.\n"},{"uri":"https://gorgonia.org/reference/vm/tapemachine/","title":"Tapemachine","tags":[],"description":"","content":" The TapeMachine is useful for executing expressions that are generally static (that is to say the computation graph does not change). Due to its static nature, the TapeMachine is good for running expressions that are compiled-once-run-many-times (such as linear regression, SVM and the like).\nTechnical details The TapeMachine pre-compiles a graph into a list of instructions, then executes the instructions linearly and sequentially. The main trade-off is dynamism. Graphs cannot be dynamically created on the fly as a re-compilation process is required (and compilation is relatively expensive). However, graphs executed with the TapeMachine run much faster as plenty of optimizations has been done in the code generation stage.\n"},{"uri":"https://gorgonia.org/about/differentiation/autodiff/","title":"Automatic Differentiation","tags":[],"description":"","content":"This page will explain how automatic differentiation works\n"},{"uri":"https://gorgonia.org/about/differentiation/symbolicdiff/","title":"Symbolic Differentiation","tags":[],"description":"","content":"This page will explain how symbolic differentiation works\n"},{"uri":"https://gorgonia.org/reference/solver/","title":"Solvers","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/","title":"main","tags":[],"description":"","content":" Gorgonia Gorgonia is a library that helps facilitate machine learning in Go.\nWrite and evaluate mathematical equations involving multidimensional arrays easily.\nIf this sounds like PyTorch or TensorFlow, it\u0026rsquo;s because the idea is quite similar.\nSpecifically, the library is pretty low-level but has higher goals like Tensorflow.\nWhy use Gorgonia? The main reason to use Gorgonia is developer comfort. If you\u0026rsquo;re using a Go stack extensively, now you have access to the ability to create production-ready machine learning systems in an environment that you are already familiar and comfortable with.\nML/AI at large is usually split into two stages: the experimental stage where one builds various models, test and retest; and the deployed state where a model after being tested and played with, is deployed. This necessitate different roles like data scientist and data engineer.\nTypically the two phases have different tools: Python (PyTorch, etc) is commonly used for the experimental stage, and then the model is rewritten in some more performant language like C++ (using dlib, mlpack etc). Of course, nowadays the gap is closing and people frequently share the tools between them. Tensorflow is one such tool that bridges the gap.\nGorgonia aims to do the same, but for the Go environment. Gorgonia is currently fairly performant - its speeds are comparable to PyTorch\u0026rsquo;s and Tensorflow\u0026rsquo;s CPU implementations. GPU implementations are a bit finnicky to compare due to the heavy cgo tax, but rest assured that this is an area of active improvement.\nHow is this website organized? This website is composed of four sections with different goals:\n Getting Started  Quick start with Gorgonia\n How Gorgonia works  Articles with a goal to explain how gorgonia works.\n Tutorials  tutorials on various use-cases\n How To  Various howto solve a specific problem with Gorgonia\n Reference guide  This is a reference guide of Gorgonia. It describes the machinery\n Vanity-import-paths  \n Miscellaneous   Video related to Gorgonia Gorgonia, A library that helps facilitate machine learning in Go - Sydney Go Meetup, September 2016 \u0026ldquo;A Funny Thing Happened On The Way To Reimplementing AlphaGo\u0026rdquo; (in Go) by Xuanyi Chew Articles mentioning Gorgonia Gorgonia (original post on Xuanyi Chew\u0026rsquo;s blog) Tensor Refactor: A Go Experience Report Think like a vertex: using Go\u0026rsquo;s concurrency for graph computation  "},{"uri":"https://gorgonia.org/reference/vm/","title":"VM","tags":[],"description":"","content":"A VM in Gorgonia is object that understands the exprgraph and has implemented the ability to do computation with it.\nTechically speaking it is an interface{} with three methods:\ntype VM interface { RunAll() error Reset() // Close closes all the machine resources (CUDA, if any, loggers if any)  Close() error } There different VMs in the current version of Gorgonia:\n Go Machine   LispMachine   Tapemachine   They function differently and take different inputs.\n"},{"uri":"https://gorgonia.org/cu/","title":"CU","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/dawson/","title":"Dawson","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/golgi/","title":"Golgi","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/gorgonia/","title":"Gorgonia","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/randomkit/","title":"RandomKit","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/tensor/","title":"Tensor","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/vecf32/","title":"vecf32","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/vecf64/","title":"vecf64","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://gorgonia.org/tags/","title":"Tags","tags":[],"description":"","content":""}]