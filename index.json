[{"uri":"/tutorials/hello-world/","title":"Hello World","tags":[],"description":"","content":" This is a step by step tutorial to do a very simple computation with Gorgonia.\nOur goal is to use all the plumbing of Gorgonia to do a simple operation:\n$ f(x,y) = x + y $\nwith x = 2 and y = 5\nhow it works The equation x + y = z can be represented as a graph:\ngraph LR; z[z] -- add(Round edge) add[+] -- x add[+] -- y  To compute the result, we use 4 steps:\n Make a similar graph with Gorgonia sets some values on the nodes x and y then instanciate a graph on a gorgonia vm extract the value from node z *  Create a graph Create an empty expression graph with this method:\ng := gorgonia.NewGraph() Create the nodes We will create some nodes and associate them to the ExprGraph.\nvar x, y, z *gorgonia.Node Create the placeholder x and y are scalar variables, we can create the corresponding node with:\nx = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;x\u0026#34;)) y = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;y\u0026#34;)) the functions take the exprgraph as argument; the resulting node is automatically associated to the graph.\n Now create the addition operator; this operator takes two nodes and returns a new node z:\nif z, err = gorgonia.Add(x, y); err != nil { log.Fatal(err) }  the returning node z is added to the graph even if g is not passed to z or to the Add function.\n Set the values We have a ExprGraph that represents the equation z = x + y. Now it\u0026rsquo;s time to assign some values to x and y.\nWe use the Let function:\ngorgonia.Let(x, 2.0) gorgonia.Let(y, 2.5) Run the graph To run the graph and compute the result, we need to instanciate a VM. Let\u0026rsquo;s use the TapeMachine:\nmachine := gorgonia.NewTapeMachine(g) defer machine.Close() and run the graph:\nif err = machine.RunAll(); err != nil { log.Fatal(err) } If a second run is needed, it is mandatory to call the Reset() method of the vm object: machine.Reset()\n Get the result Now the node z holds the result. We can extract its value by calling the Value() method:\nfmt.Printf(\u0026#34;%v\u0026#34;, z.Value()) we could also access the underlying \u0026ldquo;Go\u0026rdquo; value with a call to z.Value().Data() which would return an interface{} holding a float64 in our case\n Final result package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;gorgonia.org/gorgonia\u0026#34; ) func main() { g := gorgonia.NewGraph() var x, y, z *gorgonia.Node var err error // define the expression  x = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;x\u0026#34;)) y = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;y\u0026#34;)) if z, err = gorgonia.Add(x, y); err != nil { log.Fatal(err) } // create a VM to run the program on  machine := gorgonia.NewTapeMachine(g) defer machine.Close() // set initial values then run  gorgonia.Let(x, 2.0) gorgonia.Let(y, 2.5) if err = machine.RunAll(); err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;%v\u0026#34;, z.Value()) }$ go run main.go 4.5"},{"uri":"/getting-started/","title":"Getting Started","tags":[],"description":"","content":" Getting gorgonia Gorgonia is go-gettable and supports go modules. To get the library and its dependencies, simply run\n$ go get gorgonia.org/gorgonia First code to do a simple computation create a simple program to see if the plumbing is ok:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;gorgonia.org/gorgonia\u0026#34; ) func main() { g := gorgonia.NewGraph() var x, y, z *gorgonia.Node var err error // define the expression  x = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;x\u0026#34;)) y = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(\u0026#34;y\u0026#34;)) if z, err = gorgonia.Add(x, y); err != nil { log.Fatal(err) } // create a VM to run the program on  machine := gorgonia.NewTapeMachine(g) defer machine.Close() // set initial values then run  gorgonia.Let(x, 2.0) gorgonia.Let(y, 2.5) if err = machine.RunAll(); err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;%v\u0026#34;, z.Value()) } running the program should print the result: 4.5\nFor further explanation, please see the Hello World tutorial.\n"},{"uri":"/about/","title":"How Gorgonia works","tags":[],"description":"","content":"This section contains articles with a goal to explain how gorgonia works.\nThe articles in this section should:\n be understanding-oriented provides background and context  Analogy: an article on culinary social history\n"},{"uri":"/tutorials/","title":"Tutorials","tags":[],"description":"","content":"Various tutorials to start with various usage of Gorgonia.\nThose tutorials are:\n learning-oriented allows the newcomer to get started are a lesson  Analogy: teaching a small child how to cook\n"},{"uri":"/how-to/","title":"How To","tags":[],"description":"","content":"How to do different machine-learning things with Gorgonia.\nIn this section you will see how Gorgonia can be used to solve various problems.\nThose how-to guides:\n are goal-oriented shows how to solve a specific problem are made of understandable steps  Analogy: a recipe in a cookery book\n"},{"uri":"/reference/","title":"Reference guide","tags":[],"description":"","content":"This is the reference guide of Gorgonia. The goal of the articles in this section are:\n being information-oriented describing the machinery being accurate and complete  Analogy: a reference encyclopaedia article\n"},{"uri":"/tutorials/iris/","title":"Multivariate linear regression on Iris Dataset","tags":[],"description":"","content":" About We will use Gorgonia to create a linear regression model.\nThe goal is, to predict the species of the flowers given the caracteristics:\n sepal_length sepal_width petal_length petal_width  The species available are:\n setosa virginica versicolor  The goal of this tutorial is to use gorgonia to find the correct values of $\\Theta$ given the iris dataset, in order to write a cli utility that would look like this:\n./iris sepal length: 5 sepal width: 3.5 petal length: 1.4 sepal length: 0.2 It is probably a setosa This tutorial is for academic purpose. Its goal is to describe how to do this with Gorgonia; It is not the state of the art answer to this particular problem.\n Mathematical representation We will consider that the species if a function of its sepal length and width as well as its petal lenght and width.\nTherefore, if we consider that $y$ is the value of the species, we the equation we would like to solve is:\n$$ y = \\theta_0 + \\theta_1 * sepal\\_length + \\theta_2 * sepal\\_width + \\theta_3 * petal\\_length + \\theta_4 * petal\\_width$$\nif we consider the vectors $x$ and $\\Theta$ such as:\n$$ x = \\begin{bmatrix} sepal\\_length \u0026amp; sepal\\_width \u0026amp; petal\\_length \u0026amp; petal\\_width \u0026amp; 1\\end{bmatrix}$$\n$$ \\Theta = \\begin{bmatrix} \\theta_4 \\theta_3 \\theta_2 \\theta_1 \\theta_0 \\end{bmatrix} $$\nWe have\n$$y = x\\cdot\\Theta$$\nLinear regression To find the correct values, we will use a linear regression. We will encode the data into a matrix $X$ containing 5 columns (sepal length, sepal width, petal length, petal width and 1 for the bias). A row of the matrix represent a species.\nThe we will encode the corresponding species into a column vector $Y$ with float values.\n setosa = 1.0 virginica = 2.0 versicolor = 3.0  In the learning phase, the cost is expressed like this:\n$cost = \\dfrac{1}{m} \\sum_{i=1}^m(X^{(i)}\\cdot\\Theta-Y^{(i)})^2$\nWe will use the gradient descent to lower the cost and get the accurate values for $\\Theta$\nIt is possible to get the exact $\\theta$ values with the Normal Equation $$ \\theta = \\left( X^TX \\right)^{-1}X^TY $$ See this gist for a basic implementation with gonum.\n Generate the training set with gota (dataframe) First, let\u0026rsquo;s generate the trainig data. We use a dataframe to do this smoothly.\nSee this howto for more info about using the dataframe\n func getXYMat() (*mat.Dense, *mat.Dense) { f, err := os.Open(\u0026#34;iris.csv\u0026#34;) if err != nil { log.Fatal(err) } defer f.Close() df := dataframe.ReadCSV(f) xDF := df.Drop(\u0026#34;species\u0026#34;) toValue := func(s series.Series) series.Series { records := s.Records() floats := make([]float64, len(records)) for i, r := range records { switch r { case \u0026#34;setosa\u0026#34;: floats[i] = 1 case \u0026#34;virginica\u0026#34;: floats[i] = 2 case \u0026#34;versicolor\u0026#34;: floats[i] = 3 default: log.Fatalf(\u0026#34;unknown iris: %v\\n\u0026#34;, r) } } return series.Floats(floats) } yDF := df.Select(\u0026#34;species\u0026#34;).Capply(toValue) numRows, _ := xDF.Dims() xDF = xDF.Mutate(series.New(one(numRows), series.Float, \u0026#34;bias\u0026#34;)) fmt.Println(xDF.Describe()) fmt.Println(yDF.Describe()) return mat.DenseCopyOf(\u0026amp;matrix{xDF}), mat.DenseCopyOf(\u0026amp;matrix{yDF}) } This returns two matrices we can use in Gorgonia.\nCreate the expression graph The equation $X\\cdot\\Theta$ is represented as an ExprGraph:\nfunc getXY() (*tensor.Dense, *tensor.Dense) { x, y := getXYMat() xT := tensor.FromMat64(x) yT := tensor.FromMat64(y) // Get rid of the last dimension to create a vector \ts := yT.Shape() yT.Reshape(s[0]) return xT, yT } func main() { xT, yT := getXY() g := gorgonia.NewGraph() x := gorgonia.NodeFromAny(g, xT, gorgonia.WithName(\u0026#34;x\u0026#34;)) y := gorgonia.NodeFromAny(g, yT, gorgonia.WithName(\u0026#34;y\u0026#34;)) theta := gorgonia.NewVector( g, gorgonia.Float64, gorgonia.WithName(\u0026#34;theta\u0026#34;), gorgonia.WithShape(xT.Shape()[1]), gorgonia.WithInit(gorgonia.Uniform(0, 1))) pred := must(gorgonia.Mul(x, theta)) // Saving the value for later use  var predicted gorgonia.Value gorgonia.Read(pred, \u0026amp;predicted) Gorgonia is higly optimized; it heavily plays with pointers and memory to get good performances. Therefore, calling the Value() method of a *Node at runtime (during the execution process), may lead to incorrect results. If we need to access a specific value of a *Node at runtime (for example during the learning phase), we need to keep a reference to its underlying Value. This is why we use the Read method here. predicted will hold a Value containing the result of $X\\cdot\\Theta$ at anytime.\n Preparing the gradient computation We will use Gorgonia\u0026rsquo;s Symbolic differentiation capability.\nFirst, we will create the cost function, and use a solver to perform a gradient descent to lower the cost.\nCreate the node holding the cost We complete the exprgraph by adding the cost ($cost = \\dfrac{1}{m} \\sum_{i=1}^m(X^{(i)}\\cdot\\Theta-Y^{(i)})^2$)\nsquaredError := must(gorgonia.Square(must(gorgonia.Sub(pred, y)))) cost := must(gorgonia.Mean(squaredError)) We want to lower this cost, so we evaluate the gradient wrt to $\\Theta$:\nif _, err := gorgonia.Grad(cost, theta); err != nil { log.Fatalf(\u0026#34;Failed to backpropagate: %v\u0026#34;, err) } The gradient descent We are using the mechanism of the gradient descent. This means that we use the gradient to modulate the parameters $\\Theta$ step by step.\nThe basic gradient descent is implemented by Vanilla Solver of Gorgonia. We set the learning rate $\\gamma$ to be 0.001.\nsolver := gorgonia.NewVanillaSolver(gorgonia.WithLearnRate(0.001)) And at each step, we will ask the solver to update the $\\Theta$ parameters thanks to its gradient. Therefore, we set an update variable that we will pass to the solver at each iteration\nThe gradient descent will update the all the values passed into []gorgonia.ValueGrad at each step according this equation: ${\\displaystyle x^{(k+1)}=x^{(k)}-\\gamma \\nabla f\\left(x^{(k)}\\right)}$ It is important to understand that the solver works on Values and not on Nodes. But to make things easy, ValueGrad is an interface{} fulfiled by the *Node structure.\n In our case, we want to optimize $\\Theta$ and ask the solver will update its value like this:\n${\\displaystyle \\Theta^{(k+1)}=\\Theta^{(k)}-\\gamma \\nabla f\\left(\\Theta^{(k)}\\right)}$\nTo do so, we need to pass $\\Theta$ to the Step method of the Solver:\nupdate := []gorgonia.ValueGrad{theta} // ... if err = solver.Step(update); err != nil { log.Fatal(err) } The learning iterations Now that we have the principle, we need to run the computation with a vm several times so the gradient descent\u0026rsquo;s magic can happen.\nLet\u0026rsquo;s create a vm to execute the graph (and do the gradient computation):\nmachine := gorgonia.NewTapeMachine(g, gorgonia.BindDualValues(theta)) defer machine.Close() We will ask the solver to update the parameter $\\Theta$ wrt to its gradient. Therefore we must instruct the TapeMachine to store the value of $\\Theta$ as well as its (its dual value). We do this with the BindDualValues function.\n Now let\u0026rsquo;s create the loop and execute the graph at each step; the machine will learn!\niter := 1000000 var err error for i := 0; i \u0026lt; iter; i++ { if err = machine.RunAll(); err != nil { fmt.Printf(\u0026#34;Error during iteration: %v: %v\\n\u0026#34;, i, err) break } if err = solver.Step(model); err != nil { log.Fatal(err) } machine.Reset() // Reset is necessary in a loop like this } Getting some infos We can dump some info about the learning process by using this call\nfmt.Printf(\u0026#34;theta: %2.2f Iter: %v Cost: %2.3f Accuracy: %2.2f \\r\u0026#34;, theta.Value(), i, cost.Value(), accuracy(predicted.Data().([]float64), y.Value().Data().([]float64))) with accuracy defined like this:\nfunc accuracy(prediction, y []float64) float64 { var ok float64 for i := 0; i \u0026lt; len(prediction); i++ { if math.Round(prediction[i]-y[i]) == 0 { ok += 1.0 } } return ok / float64(len(y)) } This will display a line like this during the learning process:\ntheta: [ 0.26 -0.41 0.44 -0.62 0.83] Iter: 26075 Cost: 0.339 Accuracy: 0.61 Save the weights Once the training is done, we save the values of $\\Theta$ to be able to do some predictions:\nfunc save(value gorgonia.Value) error { f, err := os.Create(\u0026#34;theta.bin\u0026#34;) if err != nil { return err } defer f.Close() enc := gob.NewEncoder(f) err = enc.Encode(value) if err != nil { return err } return nil } Create a simple cli for predictions First, let\u0026rsquo;s load the parameters from the training phase:\nfunc main() { f, err := os.Open(\u0026#34;theta.bin\u0026#34;) if err != nil { log.Fatal(err) } defer f.Close() dec := gob.NewDecoder(f) var thetaT *tensor.Dense err = dec.Decode(\u0026amp;thetaT) if err != nil { log.Fatal(err) } Then, let\u0026rsquo;s create the model (the exprgraph) like we did before:\nA real application would probably have shared the model in a seperate package\n g := gorgonia.NewGraph() theta := gorgonia.NodeFromAny(g, thetaT, gorgonia.WithName(\u0026#34;theta\u0026#34;)) values := make([]float64, 5) xT := tensor.New(tensor.WithBacking(values)) x := gorgonia.NodeFromAny(g, xT, gorgonia.WithName(\u0026#34;x\u0026#34;)) y, err := gorgonia.Mul(x, theta) Then enter a for loop that will get info from stdin, do the computation and display the result:\nmachine := gorgonia.NewTapeMachine(g) values[4] = 1.0 for { values[0] = getInput(\u0026#34;sepal length\u0026#34;) values[1] = getInput(\u0026#34;sepal widt\u0026#34;) values[2] = getInput(\u0026#34;petal length\u0026#34;) values[3] = getInput(\u0026#34;petal width\u0026#34;) if err = machine.RunAll(); err != nil { log.Fatal(err) } switch math.Round(y.Value().Data().(float64)) { case 1: fmt.Println(\u0026#34;It is probably a setosa\u0026#34;) case 2: fmt.Println(\u0026#34;It is probably a virginica\u0026#34;) case 3: fmt.Println(\u0026#34;It is probably a versicolor\u0026#34;) default: fmt.Println(\u0026#34;unknown iris\u0026#34;) } machine.Reset() } This is a helper function to get the input:\nfunc getInput(s string) float64 { reader := bufio.NewReader(os.Stdin) fmt.Printf(\u0026#34;%v: \u0026#34;, s) text, _ := reader.ReadString(\u0026#39;\\n\u0026#39;) text = strings.Replace(text, \u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;, -1) input, err := strconv.ParseFloat(text, 64) if err != nil { log.Fatal(err) } return input } Now we can go build or go run the code, and voil√†! We have a fully autonomous cli that can predict the iris species regarding its features:\n$ go run main.go sepal length: 4.4 sepal widt: 2.9 petal length: 1.4 petal width: 0.2 It is probably a setosa sepal length: 5.9 sepal widt: 3.0 petal length: 5.1 petal width: 1.8 It is probably a virginica Conclusion This is a step by step example. You can now play with the init values of theta, or change to solver to see how thing goes within Gorgonia.\nThe full code can be found in the example of the Gorgonia project.\nBonus: visual representation It is possible to visualize the dataset using the gonum plotter libraries. Here is a simple example on how to achieve it:\nimport ( \u0026#34;gonum.org/v1/plot\u0026#34; \u0026#34;gonum.org/v1/plot/plotter\u0026#34; \u0026#34;gonum.org/v1/plot/plotutil\u0026#34; \u0026#34;gonum.org/v1/plot/vg\u0026#34; \u0026#34;gonum.org/v1/plot/vg/draw\u0026#34; ) func plotData(x []float64, a []float64) []byte { p, err := plot.New() if err != nil { log.Fatal(err) } p.Title.Text = \u0026#34;sepal length \u0026amp; width\u0026#34; p.X.Label.Text = \u0026#34;length\u0026#34; p.Y.Label.Text = \u0026#34;width\u0026#34; p.Add(plotter.NewGrid()) l := len(x) / len(a) for k := 1; k \u0026lt;= 3; k++ { data0 := make(plotter.XYs, 0) for i := 0; i \u0026lt; len(a); i++ { if k != int(a[i]) { continue } x1 := x[i*l+0] // sepal_length \ty1 := x[i*l+1] // sepal_width \tdata0 = append(data0, plotter.XY{X: x1, Y: y1}) } data, err := plotter.NewScatter(data0) if err != nil { log.Fatal(err) } data.GlyphStyle.Color = plotutil.Color(k - 1) data.Shape = \u0026amp;draw.PyramidGlyph{} p.Add(data) p.Legend.Add(fmt.Sprint(k), data) } w, err := p.WriterTo(4*vg.Inch, 4*vg.Inch, \u0026#34;png\u0026#34;) if err != nil { panic(err) } var b bytes.Buffer writer := bufio.NewWriter(\u0026amp;b) w.WriteTo(writer) ioutil.WriteFile(\u0026#34;out.png\u0026#34;, b.Bytes(), 0644) return b.Bytes() }"},{"uri":"/how-to/dataframe/","title":"Create a tensor from a Dataframe (gota)","tags":[],"description":"","content":" This howto explains how to create a tensor from a dataframe using gota The goal is to read a csv file and create a *tensor.Dense with shape (2,2).\nCreate the dataframe from a csv file Consider a csv file with the following content:\nsepal_length,sepal_width,petal_length,petal_width,species 5.1 ,3.5 ,1.4 ,0.2 ,setosa 4.9 ,3.0 ,1.4 ,0.2 ,setosa 4.7 ,3.2 ,1.3 ,0.2 ,setosa 4.6 ,3.1 ,1.5 ,0.2 ,setosa 5.0 ,3.6 ,1.4 ,0.2 ,setosa ... This is extract from the Iris flower data set. A copy of the dataset can be found here\n We want to create a tensor with all values but the species.\nCreate the dataframe with gota. gota\u0026rsquo;s dataframe package has a function ReadCSV that takes an io.Reader as argument.\nf, err := os.Open(\u0026#34;iris.csv\u0026#34;) if err != nil { log.Fatal(err) } defer f.Close() df := dataframe.ReadCSV(f) df is a DataFrame that contains all the data present in the file.\ngota uses te first line of the CSV to reference the columns in the dataframe\n Let\u0026rsquo;s remove the species column:\nxDF := df.Drop(\u0026#34;species\u0026#34;) Convert the dataframe into a matrix To make things easier, we will convert our dataframe into a Matrix as defined by gonum (see the matrix godoc). matrix is an interface. gota\u0026rsquo;s dataframe does not fulfill the Matrix interface. As described into gota\u0026rsquo;s documentation, we create a wrapper around DataFrame to fulfil the Matrix interface.\ntype matrix struct { dataframe.DataFrame } func (m matrix) At(i, j int) float64 { return m.Elem(i, j).Float() } func (m matrix) T() mat.Matrix { return mat.Transpose{Matrix: m} } Create the tensor Now we can create a *Dense tensor thanks to the function tensor.FromMat64 by wrapping the dataframe into the matrix structure.\nxT := tensor.FromMat64(mat.DenseCopyOf(\u0026amp;matrix{xDF}))"},{"uri":"/reference/tensor/","title":"Tensor","tags":[],"description":"","content":""},{"uri":"/reference/solver/","title":"Solvers","tags":[],"description":"","content":""},{"uri":"/","title":"main","tags":[],"description":"","content":" Gorgonia Gorgonia is a library that helps facilitate machine learning in Go.\nWrite and evaluate mathematical equations involving multidimensional arrays easily.\nIf this sounds like Theano or TensorFlow, it\u0026rsquo;s because the idea is quite similar.\nSpecifically, the library is pretty low-level, like Theano, but has higher goals like Tensorflow.\nWhy use Gorgonia? The main reason to use Gorgonia is developer comfort. If you\u0026rsquo;re using a Go stack extensively, now you have access to the ability to create production-ready machine learning systems in an environment that you are already familiar and comfortable with.\nML/AI at large is usually split into two stages: the experimental stage where one builds various models, test and retest; and the deployed state where a model after being tested and played with, is deployed. This necessitate different roles like data scientist and data engineer.\nTypically the two phases have different tools: Python/Lua (using Theano, Torch, etc) is commonly used for the experimental stage, and then the model is rewritten in some more performant language like C++ (using dlib, mlpack etc). Of course, nowadays the gap is closing and people frequently share the tools between them. Tensorflow is one such tool that bridges the gap.\nGorgonia aims to do the same, but for the Go environment. Gorgonia is currently fairly performant - its speeds are comparable to Theano\u0026rsquo;s and Tensorflow\u0026rsquo;s CPU implementations. GPU implementations are a bit finnicky to compare due to the heavy cgo tax, but rest assured that this is an area of active improvement.\nHow is this website organized? This website is composed of four sections with different goals:\n about contains all the informations about how Gorgonia works reference How To Tutorials  "},{"uri":"/reference/vm/","title":"VM","tags":[],"description":"","content":""},{"uri":"/cu/","title":"CU","tags":[],"description":"","content":""},{"uri":"/dawson/","title":"Dawson","tags":[],"description":"","content":""},{"uri":"/golgi/","title":"Golgi","tags":[],"description":"","content":""},{"uri":"/gorgonia/","title":"Gorgonia","tags":[],"description":"","content":""},{"uri":"/randomkit/","title":"RandomKit","tags":[],"description":"","content":""},{"uri":"/tensor/","title":"Tensor","tags":[],"description":"","content":""},{"uri":"/vanity-import-paths/","title":"Vanity-import-paths","tags":[],"description":"","content":""},{"uri":"/vecf32/","title":"vecf32","tags":[],"description":"","content":""},{"uri":"/vecf64/","title":"vecf64","tags":[],"description":"","content":""},{"uri":"/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"/tags/","title":"Tags","tags":[],"description":"","content":""}]