<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>main on Gorgonia</title><link>https://gorgonia.org/</link><description>Recent content in main on Gorgonia</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Tue, 29 Oct 2019 14:59:59 +0100</lastBuildDate><atom:link href="https://gorgonia.org/index.xml" rel="self" type="application/rss+xml"/><item><title>Computation Graph</title><link>https://gorgonia.org/about/computation-graph/</link><pubDate>Sun, 10 Nov 2019 21:09:19 +0100</pubDate><guid>https://gorgonia.org/about/computation-graph/</guid><description>Gorgonia is Graph based Note: this article takes its inspiration from this blog post
Like most deep learning libraries such as Tensorflow or Theano, Gorgonia rely on the concept that equations are representable by graphs.
It expose the equation graph as an ExprGraph object that can be manipulated by the programmer.
So instead of writing:
func main() { fmt.Printf(&amp;#34;%v&amp;#34;, 1+1) } the programmer should write:
func main() { // Create a graph.</description></item><item><title>Graph / Exprgraph</title><link>https://gorgonia.org/reference/exprgraph/</link><pubDate>Tue, 29 Oct 2019 19:49:05 +0100</pubDate><guid>https://gorgonia.org/reference/exprgraph/</guid><description>A lot has been said about a computation graph or an expression graph. But what is it exactly? Think of it as an AST for the math expression that you want. Here&amp;rsquo;s the graph for the examples (but with a vector and a scalar addition instead) above:
By the way, Gorgonia comes with nice-ish graph printing abilities. Here&amp;rsquo;s an example of a graph of the equation $y = x^2$ and its derivation:</description></item><item><title>Hello World</title><link>https://gorgonia.org/tutorials/hello-world/</link><pubDate>Tue, 29 Oct 2019 17:54:31 +0100</pubDate><guid>https://gorgonia.org/tutorials/hello-world/</guid><description>This is a step by step tutorial to do a very simple computation with Gorgonia.
Our goal is to use all the plumbing of Gorgonia to do a simple operation:
$ f(x,y) = x + y $
with x = 2 and y = 5
how it works The equation x + y = z can be represented as a graph:
graph LR; z[z] -- add(Round edge) add[+] -- x add[+] -- y To compute the result, we use 4 steps:</description></item><item><title>Simple Convolution Neural Net (MNIST)</title><link>https://gorgonia.org/tutorials/mnist/</link><pubDate>Tue, 29 Oct 2019 20:09:05 +0100</pubDate><guid>https://gorgonia.org/tutorials/mnist/</guid><description>About This a step by step tutorial to build and train a convolution neural network on the MNIST dataset.
The complete code can be found in the examples directory of the principal Gorgonia repository. The goal of this tutorial is to explain in detail the code. Further explanation of how it works can be found in the book Go Machine Learning Projects
The dataset This part is about loading and printing the dataset.</description></item><item><title>Present</title><link>https://gorgonia.org/reference/present/</link><pubDate>Mon, 04 Nov 2019 09:38:27 +0100</pubDate><guid>https://gorgonia.org/reference/present/</guid><description> This page contains material that can be used within presentation.
Logos Logos logo_g.svg (22 ko) logo_g_square.png (142 ko) logo_horizontal.svg (25 ko) logo_vertical.svg (25 ko)</description></item><item><title>Convnet with CUDA</title><link>https://gorgonia.org/tutorials/mnist-cuda/</link><pubDate>Sun, 16 Feb 2020 22:08:40 +0100</pubDate><guid>https://gorgonia.org/tutorials/mnist-cuda/</guid><description>This tutorial describes how to run the simple convolutional neural network on a GPU.
The example used in this tutorial is based on MNIST. Your development environment should be ready as described in the tutorial &amp;ldquo;Simple convolution neural net (mnist)&amp;rdquo;
Preparing the CUDA binding The CUDA binding relies on CGO and the official CUDA toolkit. You can install it manually or, if you use AWS, you can rely on an AMI with all the pre-requisites.</description></item><item><title>Ubiquitous Language and glossary</title><link>https://gorgonia.org/getting-started/ubiquitous-language/</link><pubDate>Wed, 05 Feb 2020 16:45:51 +0100</pubDate><guid>https://gorgonia.org/getting-started/ubiquitous-language/</guid><description>This page holds various definitions and glossary that will help you to understand Gorgonia and to communicate with the team (via PR or issues)
Tensors inner(most) dimension(s) - given a shape, the inner dimensions tend to the right. e.g. in a shape (2,3,4), the inner dimensions are (3, 4). The innermost dimension is 4. outer(most) dimension(s) - given a shape, the outer dimensions tend to the left . e.</description></item><item><title>Start contributing to the doc</title><link>https://gorgonia.org/getting-started/contributing-doc/</link><pubDate>Fri, 31 Jan 2020 14:59:03 +0100</pubDate><guid>https://gorgonia.org/getting-started/contributing-doc/</guid><description>If you want to get started contributing to the Gorgonia documentation, this page and its linked topics can help you get started. You don&amp;rsquo;t need to be a developer or a technical writer to make a big impact on the Gorgonia documentation and user experience! All you need for the topics on this page is a GitHub account and a web browser.
If you&amp;rsquo;re looking for information on how to start contributing to Gorgonia code repositories, refer to the Contribution guidelines.</description></item><item><title>Drawing the ExprGraph with Graphviz (dot)</title><link>https://gorgonia.org/how-to/dot/</link><pubDate>Sun, 01 Dec 2019 10:14:55 +0100</pubDate><guid>https://gorgonia.org/how-to/dot/</guid><description>The encoding package of Gorgonia contains a function to marshal the ExprGraph into the dot language.
This make it possible to use the graphviz program to generate png or svg versions of the graph.
A simple way to do it:
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;gorgonia.org/gorgonia&amp;#34; &amp;#34;gorgonia.org/gorgonia/encoding/dot&amp;#34; ) func main() { g := gorgonia.NewGraph() var x, y *gorgonia.Node // define the expression x = gorgonia.NewScalar(g, gorgonia.Float64, gorgonia.WithName(&amp;#34;x&amp;#34;)) y = gorgonia.</description></item><item><title>Multivariate linear regression on Iris Dataset</title><link>https://gorgonia.org/tutorials/iris/</link><pubDate>Thu, 31 Oct 2019 14:53:37 +0100</pubDate><guid>https://gorgonia.org/tutorials/iris/</guid><description>About We will use Gorgonia to create a linear regression model.
The goal is, to predict the species of the Iris flowers given the characteristics:
sepal_length sepal_width petal_length petal_width The species we want to predict are:
setosa virginica versicolor The goal of this tutorial is to use Gorgonia to find the correct values of $\Theta$ given the iris dataset, in order to write a CLI utility that would look like this:</description></item><item><title>Create a tensor from a Dataframe (gota)</title><link>https://gorgonia.org/how-to/dataframe/</link><pubDate>Wed, 30 Oct 2019 22:57:09 +0100</pubDate><guid>https://gorgonia.org/how-to/dataframe/</guid><description>This howto explains how to create a tensor from a dataframe using gota The goal is to read a csv file and create a *tensor.Dense with shape (2,2).
Create the dataframe from a csv file Consider a csv file with the following content:
sepal_length,sepal_width,petal_length,petal_width,species 5.1 ,3.5 ,1.4 ,0.2 ,setosa 4.9 ,3.0 ,1.4 ,0.2 ,setosa 4.7 ,3.2 ,1.3 ,0.2 ,setosa 4.6 ,3.1 ,1.5 ,0.2 ,setosa 5.0 ,3.6 ,1.4 ,0.2 ,setosa .</description></item><item><title>Save Weights</title><link>https://gorgonia.org/how-to/save-weights/</link><pubDate>Tue, 29 Oct 2019 20:07:16 +0100</pubDate><guid>https://gorgonia.org/how-to/save-weights/</guid><description>Goal The goal of this howto is to describe a way to save the values of the nodes and to restore them.
Implementation The best thing you can do right now is to save the value of the corresponding nodes and restore them.
The tensors are fulfilling the GobEncode and GobDecode interface and this is the best option. You can also save the backend as a slice of elements but this is a little bit trickier.</description></item><item><title>LispMachine</title><link>https://gorgonia.org/reference/vm/lispmachine/</link><pubDate>Tue, 29 Oct 2019 19:50:15 +0100</pubDate><guid>https://gorgonia.org/reference/vm/lispmachine/</guid><description>The LispMachine was designed to take a graph as an input, and executes directly on the nodes of the graph. If the graph change, simply create a new lightweight LispMachine to execute it on. The LispMachine is suitable for tasks such as creating recurrent neural networks without a fixed size.
The trade-off is that executing a graph on LispMachine is generally slower than on TapeMachine, given the same static &amp;ldquo;image&amp;rdquo; of a graph.</description></item><item><title>Tapemachine</title><link>https://gorgonia.org/reference/vm/tapemachine/</link><pubDate>Tue, 29 Oct 2019 19:50:15 +0100</pubDate><guid>https://gorgonia.org/reference/vm/tapemachine/</guid><description>The TapeMachine is useful for executing expressions that are generally static (that is to say the computation graph does not change). Due to its static nature, the TapeMachine is good for running expressions that are compiled-once-run-many-times (such as linear regression, SVM and the like).
Technical details The TapeMachine pre-compiles a graph into a list of instructions, then executes the instructions linearly and sequentially. The main trade-off is dynamism. Graphs cannot be dynamically created on the fly as a re-compilation process is required (and compilation is relatively expensive).</description></item><item><title>Automatic Differentiation</title><link>https://gorgonia.org/about/differentiation/autodiff/</link><pubDate>Tue, 29 Oct 2019 19:49:25 +0100</pubDate><guid>https://gorgonia.org/about/differentiation/autodiff/</guid><description>This page will explain how automatic differentiation works</description></item><item><title>Symbolic Differentiation</title><link>https://gorgonia.org/about/differentiation/symbolicdiff/</link><pubDate>Tue, 29 Oct 2019 19:49:25 +0100</pubDate><guid>https://gorgonia.org/about/differentiation/symbolicdiff/</guid><description>This page will explain how symbolic differentiation works</description></item><item><title>CU</title><link>https://gorgonia.org/cu/</link><pubDate>Mon, 28 Oct 2019 11:41:02 +0100</pubDate><guid>https://gorgonia.org/cu/</guid><description/></item><item><title>Dawson</title><link>https://gorgonia.org/dawson/</link><pubDate>Mon, 28 Oct 2019 11:41:02 +0100</pubDate><guid>https://gorgonia.org/dawson/</guid><description/></item><item><title>Golgi</title><link>https://gorgonia.org/golgi/</link><pubDate>Mon, 28 Oct 2019 11:41:02 +0100</pubDate><guid>https://gorgonia.org/golgi/</guid><description/></item><item><title>Gorgonia</title><link>https://gorgonia.org/gorgonia/</link><pubDate>Mon, 28 Oct 2019 11:41:02 +0100</pubDate><guid>https://gorgonia.org/gorgonia/</guid><description/></item><item><title>RandomKit</title><link>https://gorgonia.org/randomkit/</link><pubDate>Mon, 28 Oct 2019 11:41:02 +0100</pubDate><guid>https://gorgonia.org/randomkit/</guid><description/></item><item><title>Tensor</title><link>https://gorgonia.org/tensor/</link><pubDate>Mon, 28 Oct 2019 11:41:02 +0100</pubDate><guid>https://gorgonia.org/tensor/</guid><description/></item><item><title>vecf32</title><link>https://gorgonia.org/vecf32/</link><pubDate>Mon, 28 Oct 2019 11:41:02 +0100</pubDate><guid>https://gorgonia.org/vecf32/</guid><description/></item><item><title>vecf64</title><link>https://gorgonia.org/vecf64/</link><pubDate>Mon, 28 Oct 2019 11:41:02 +0100</pubDate><guid>https://gorgonia.org/vecf64/</guid><description/></item></channel></rss>